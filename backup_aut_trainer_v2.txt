# automatic_confirmation_trainer.py - TRAINER AUTOM√ÅTICO SIN CONFIRMACI√ìN MANUAL
# BASADO EN: manual_confirmation_trainer.py pero con decisiones autom√°ticas
# REGLAS: Mayor confianza gana, excepci√≥n para 'amount' prioriza LOCAL siempre

import pandas as pd
import os
import sys
import re
from typing import Dict, List, Optional, Tuple, Any
import logging
from datetime import datetime
import json
from pathlib import Path
import yaml

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AutomaticConfirmationTrainingSession:
    """Sesi√≥n de entrenamiento AUTOM√ÅTICO - sin confirmaci√≥n manual"""
    
    def __init__(self, csv_file: str, erp_hint: str = None):
        self.csv_file = csv_file
        self.erp_hint = erp_hint
        self.df = None
        self.mapper = None
        self.detector = None
        
        # MISMOS CAMPOS EST√ÅNDAR que manual trainer
        self.standard_fields = [
            'journal_entry_id', 'line_number', 'description', 'line_description',
            'posting_date', 'fiscal_year', 'period_number', 'gl_account_number',
            'amount', 'debit_amount', 'credit_amount', 'debit_credit_indicator',
            'prepared_by', 'entry_date', 'entry_time', 'gl_account_name', 'vendor_id'
        ]
        
        # Estad√≠sticas de entrenamiento autom√°tico
        self.training_stats = {
            'columns_processed': 0,
            'automatic_mappings': 0,
            'conflicts_resolved': 0,
            'amount_conflicts_resolved': 0,
            'high_confidence_mappings': 0,
            'low_confidence_mappings': 0,
            'rejected_low_confidence': 0,  # NUEVO: rechazados por baja confianza
            'unmapped_columns': 0,
            'synonyms_added': 0,
            'regex_patterns_added': 0
        }
        
        # Umbral de confianza m√≠nimo
        self.confidence_threshold = 0.75
        
        # Decisiones autom√°ticas registradas (compatible con manual trainer)
        self.user_decisions = {}  # Mantenemos el mismo nombre para compatibilidad
        self.learned_patterns = {}
        self.new_synonyms = {}
        self.new_regex_patterns = {}
        self.conflict_resolutions = {}
        
        # Archivos de configuraci√≥n (MISMOS que manual trainer)
        self.yaml_config_file = "config/pattern_learning_config.yaml"
        self.dynamic_fields_file = "config/dynamic_fields_config.yaml"
        
    def initialize(self) -> bool:
        """Inicializa la sesi√≥n de entrenamiento autom√°tico"""
        try:
            print(f"Initializing AUTOMATIC TRAINING Session...")
            print(f"File: {self.csv_file}")
            print(f"ERP Hint: {self.erp_hint or 'Auto-detect'}")
            print(f"Mode: AUTOMATIC (no manual confirmation)")
            print(f"Confidence resolution: Highest confidence wins")
            print(f"Confidence threshold: Only mappings > {self.confidence_threshold} will be included")
            print(f"Amount exception: Prioritize 'local' ALWAYS in name")
            
            # Verificar archivo
            if not os.path.exists(self.csv_file):
                print(f"File not found: {self.csv_file}")
                return False
            
            # Cargar CSV
            self.df = pd.read_csv(self.csv_file, encoding='utf-8')
            print(f"Loaded {len(self.df)} rows x {len(self.df.columns)} columns")
            
            # Importar m√≥dulos del sistema (MISMOS que manual trainer)
            try:
                from core.field_mapper import FieldMapper
                from core.field_detector import FieldDetector
                
                self.mapper = FieldMapper()
                self.detector = FieldDetector()
                print("System modules imported successfully")
                
            except ImportError as e:
                print(f"Failed to import system modules: {e}")
                return False
            
            # Cargar configuraci√≥n de patrones aprendidos
            self._load_learned_patterns()
            
            return True
            
        except Exception as e:
            print(f"Initialization failed: {e}")
            return False
    
    def _load_learned_patterns(self):
        """Carga patrones previamente aprendidos (IGUAL que manual trainer)"""
        try:
            if os.path.exists(self.yaml_config_file):
                with open(self.yaml_config_file, 'r', encoding='utf-8') as f:
                    config = yaml.safe_load(f)
                    self.learned_patterns = config.get('learned_patterns', {})
                    print(f"Loaded {len(self.learned_patterns)} learned patterns")
            else:
                print("No previous learned patterns found")
        except Exception as e:
            print(f"Could not load learned patterns: {e}")
            self.learned_patterns = {}
    
    def run_automatic_training(self) -> Dict:
        """Ejecuta el entrenamiento autom√°tico SIN confirmaci√≥n manual"""
        try:
            print(f"\nStarting AUTOMATIC FIELD TRAINING...")
            print(f"=" * 55)
            print(f"All decisions will be made automatically based on confidence")
            print(f"Special rule for 'amount': prioritize 'local' columns ALWAYS")
            print(f"Confidence threshold: {self.confidence_threshold} (only mappings above this will be included)")
            
            # An√°lisis inicial del DataFrame (IGUAL que manual trainer)
            print(f"CSV Columns ({len(self.df.columns)}):")
            for i, col in enumerate(self.df.columns, 1):
                print(f"  {i:2d}. {col}")
            print()
            
            # NUEVO ENFOQUE: Una sola pasada usando el mapper directamente
            print(f"Processing all columns using field mapper...")
            print("-" * 50)
            
            all_mappings = {}  # column_name -> (field_type, confidence)
            field_conflicts = {}  # field_type -> [(column_name, confidence), ...]
            
            # Procesar cada columna usando SOLO field_mapper
            for column_name in self.df.columns:
                print(f"Processing: '{column_name}'")
                
                try:
                    # Usar mapper directamente (como en manual trainer)
                    sample_data = self.df[column_name].dropna().head(100)
                    mapping_result = self.mapper.find_field_mapping(
                        column_name,
                        self.erp_hint,
                        sample_data=sample_data
                    )
                    
                    if mapping_result:
                        field_type, confidence = mapping_result
                        
                        # FILTRO DE CONFIANZA: Solo incluir si confianza > threshold
                        if confidence > self.confidence_threshold:
                            # Solo incluir si est√° en nuestros campos est√°ndar
                            if field_type in self.standard_fields:
                                all_mappings[column_name] = (field_type, confidence)
                                
                                # Registrar para detecci√≥n de conflictos
                                if field_type not in field_conflicts:
                                    field_conflicts[field_type] = []
                                field_conflicts[field_type].append((column_name, confidence))
                                
                                print(f"  ‚úì {field_type} (confidence: {confidence:.3f}) - ACCEPTED")
                            else:
                                print(f"  ‚Üí {field_type} (not in standard fields - skipped)")
                        else:
                            print(f"  ‚úó {field_type} (confidence: {confidence:.3f}) - REJECTED (below {self.confidence_threshold})")
                            self.training_stats['rejected_low_confidence'] += 1
                    else:
                        print(f"  ‚Üí No mapping found")
                    
                    self.training_stats['columns_processed'] += 1
                    
                except Exception as e:
                    print(f"  ‚Üí Error processing column: {e}")
                    logger.warning(f"Error processing column {column_name}: {e}")
            
            print(f"\nConflict Detection Results:")
            print("-" * 30)
            
            # Detectar y resolver conflictos
            final_mappings = {}
            for field_type, candidates in field_conflicts.items():
                if len(candidates) == 1:
                    # No hay conflicto
                    column_name, confidence = candidates[0]
                    final_mappings[column_name] = {
                        'field_type': field_type,
                        'confidence': confidence,
                        'resolution_type': 'no_conflict'
                    }
                    print(f"  {field_type}: '{column_name}' (no conflict)")
                else:
                    # HAY CONFLICTO - resolver autom√°ticamente
                    print(f"  CONFLICT - {field_type}: {len(candidates)} candidates")
                    for col, conf in candidates:
                        print(f"    '{col}': {conf:.3f}")
                    
                    winner = self._resolve_single_conflict_automatically(field_type, candidates)
                    if winner:
                        column_name, confidence, resolution_type = winner
                        final_mappings[column_name] = {
                            'field_type': field_type,
                            'confidence': confidence,
                            'resolution_type': resolution_type
                        }
                        
                        # Registrar resoluci√≥n de conflicto
                        self.conflict_resolutions[field_type] = {
                            'winner': column_name,
                            'all_candidates': candidates,
                            'resolution_type': resolution_type
                        }
                        
                        self.training_stats['conflicts_resolved'] += 1
                        
                        if field_type == 'amount':
                            self.training_stats['amount_conflicts_resolved'] += 1
                        
                        print(f"    WINNER: '{column_name}' ({resolution_type})")
            
            # Actualizar user_decisions desde mappings finales
            self._update_user_decisions_from_mappings(final_mappings)
            
            # Finalizar entrenamiento
            result = self._finalize_automatic_training()
            
            return result
            
        except Exception as e:
            print(f"Automatic training failed: {e}")
            import traceback
            traceback.print_exc()
            return {'success': False, 'error': str(e)}
    
    def _resolve_single_conflict_automatically(self, field_type: str, candidates: List[Tuple[str, float]]) -> Optional[Tuple[str, float, str]]:
        """Resuelve un conflicto espec√≠fico autom√°ticamente"""
        # REGLA ESPECIAL PARA AMOUNT: Priorizar columnas con 'local' SIEMPRE
        if field_type == 'amount':
            amount_winner = self._resolve_amount_conflict(candidates)
            if amount_winner:
                return amount_winner
        
        # REGLA GENERAL: Mayor confianza gana
        candidates_sorted = sorted(candidates, key=lambda x: x[1], reverse=True)
        winner_column, winner_confidence = candidates_sorted[0]
        
        return (winner_column, winner_confidence, 'highest_confidence')
    
    def _resolve_amount_conflict(self, candidates: List[Tuple[str, float]]) -> Optional[Tuple[str, float, str]]:
        """Resuelve conflictos espec√≠ficamente para el campo 'amount' - PRIORIDAD ABSOLUTA A 'local'"""
        print(f"    RESOLVING AMOUNT CONFLICT - checking for 'local' priority...")
        
        # PASO 1: Buscar candidatos que contengan 'local' (PRIORIDAD ABSOLUTA)
        local_candidates = []
        
        for column_name, confidence in candidates:
            column_lower = column_name.lower()
            
            # Verificar si contiene la palabra 'local'
            if 'local' in column_lower:
                local_candidates.append((column_name, confidence, 'amount_priority_local_ABSOLUTE'))
                print(f"    FOUND LOCAL CANDIDATE: '{column_name}' (confidence: {confidence:.3f})")
        
        # Si hay candidatos con 'local', elegir el de mayor confianza entre ellos
        # IMPORTANTE: 'local' SIEMPRE gana, sin importar otras consideraciones
        if local_candidates:
            best_local = max(local_candidates, key=lambda x: x[1])
            print(f"    LOCAL PRIORITY RULE ACTIVATED: '{best_local[0]}' WINS (contains 'local')")
            return best_local
        
        # PASO 2: Si no hay candidatos con 'local', buscar ml, lm (prioridad secundaria)
        priority_keywords = ['ml', 'lm']
        priority_candidates = []
        
        for column_name, confidence in candidates:
            column_lower = column_name.lower()
            
            # Verificar si contiene alguna palabra clave prioritaria
            for keyword in priority_keywords:
                if keyword in column_lower:
                    priority_candidates.append((column_name, confidence, f'amount_priority_{keyword}'))
                    print(f"    FOUND PRIORITY CANDIDATE: '{column_name}' (contains '{keyword}')")
                    break
        
        # Si hay candidatos prioritarios, elegir el de mayor confianza entre ellos
        if priority_candidates:
            best_priority = max(priority_candidates, key=lambda x: x[1])
            print(f"    PRIORITY RULE: '{best_priority[0]}' contains '{best_priority[2].split('_')[-1]}'")
            return best_priority
        
        # PASO 3: Si no hay candidatos prioritarios, usar regla general (mayor confianza)
        candidates_sorted = sorted(candidates, key=lambda x: x[1], reverse=True)
        winner_column, winner_confidence = candidates_sorted[0]
        
        print(f"    FALLBACK RULE: '{winner_column}' has highest confidence ({winner_confidence:.3f})")
        return (winner_column, winner_confidence, 'amount_highest_confidence')
    
    def _update_user_decisions_from_mappings(self, final_mappings: Dict):
        """Actualiza user_decisions basado en mapeos finales (compatible con manual trainer)"""
        for column_name, mapping_info in final_mappings.items():
            field_type = mapping_info['field_type']
            confidence = mapping_info['confidence']
            resolution_type = mapping_info['resolution_type']
            
            # Determinar tipo de decisi√≥n autom√°tica
            if resolution_type == 'no_conflict':
                decision_type = 'automatic_no_conflict'
            else:
                decision_type = f'automatic_{resolution_type}'
            
            self.user_decisions[column_name] = {
                'field_type': field_type,
                'confidence': confidence,
                'decision_type': decision_type,
                'resolution_type': resolution_type
            }
            
            # Actualizar estad√≠sticas
            if confidence > 0.8:
                self.training_stats['high_confidence_mappings'] += 1
            else:
                self.training_stats['low_confidence_mappings'] += 1
                
            self.training_stats['automatic_mappings'] += 1
    
    def _finalize_automatic_training(self) -> Dict:
        """Finaliza el entrenamiento autom√°tico y genera resultados (FORMATO COMPATIBLE)"""
        try:
            print(f"\nAUTOMATIC TRAINING FINALIZATION")
            print(f"=" * 40)
            
            # Generar tabla de mapeo final (IGUAL que manual trainer)
            mapping_table = self._generate_mapping_table()
            
            # Generar reporte
            report = self._generate_training_report()
            
            # Crear CSV transformados (MISMA FUNCI√ìN que manual trainer)
            csv_result = self._create_transformed_csv()
            
            return {
                'success': True,
                'training_stats': self.training_stats,
                'user_decisions': self.user_decisions,  # Compatible con manual trainer
                'learned_patterns': self.learned_patterns,
                'conflict_resolutions': self.conflict_resolutions,
                'report_file': report,
                'header_csv': csv_result.get('header_file') if isinstance(csv_result, dict) else None,
                'detail_csv': csv_result.get('detail_file') if isinstance(csv_result, dict) else None,
                'csv_info': csv_result.get('csv_info') if isinstance(csv_result, dict) else None
            }
            
        except Exception as e:
            print(f"Finalization failed: {e}")
            return {'success': False, 'error': str(e)}
    
    def _generate_mapping_table(self) -> str:
        """Genera tabla de mapeo final (IGUAL que manual trainer)"""
        try:
            table_lines = []
            table_lines.append(f"{'Campo Est√°ndar':<25} | {'Columna Mapeada':<30} | {'Confianza':<10}")
            table_lines.append(f"{'-'*25} | {'-'*30} | {'-'*10}")
            
            for standard_field in self.standard_fields:
                mapped_column = "No mapeado"
                confidence = "0.000"
                
                for column_name, decision in self.user_decisions.items():
                    if decision['field_type'] == standard_field:
                        mapped_column = column_name
                        confidence = f"{decision['confidence']:.3f}"
                        break
                
                table_lines.append(f"{standard_field:<25} | {mapped_column:<30} | {confidence:<10}")
            
            table_str = "\n".join(table_lines)
            print(f"\nFINAL MAPPING TABLE:")
            print(table_str)
            
            return table_str
            
        except Exception as e:
            print(f"Could not generate mapping table: {e}")
            return ""
    
    def _generate_training_report(self) -> str:
        """Genera reporte de entrenamiento autom√°tico (FORMATO COMPATIBLE)"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            report_file = f"automatic_training_report_{timestamp}.txt"
            
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(f"AUTOMATIC FIELD TRAINING SESSION REPORT\n")
                f.write(f"=" * 50 + "\n\n")
                
                f.write(f"Session Information:\n")
                f.write(f"  CSV File: {self.csv_file}\n")
                f.write(f"  ERP Hint: {self.erp_hint or 'Auto-detect'}\n")
                f.write(f"  Standard Fields: {len(self.standard_fields)}\n")
                f.write(f"  Mode: AUTOMATIC (no manual confirmation)\n")
                f.write(f"  Timestamp: {datetime.now().isoformat()}\n\n")
                
                f.write(f"Training Statistics:\n")
                for key, value in self.training_stats.items():
                    f.write(f"  {key.replace('_', ' ').title()}: {value}\n")
                f.write("\n")
                
                f.write(f"Automatic Decisions:\n")
                for column, decision in self.user_decisions.items():
                    f.write(f"  {column}: {decision['field_type']} ")
                    f.write(f"(confidence: {decision['confidence']:.3f}, ")
                    f.write(f"type: {decision['decision_type']})\n")
                f.write("\n")
                
                f.write(f"Conflict Resolutions:\n")
                for field_type, resolution in self.conflict_resolutions.items():
                    f.write(f"  {field_type}:\n")
                    f.write(f"    Winner: {resolution['winner']}\n")
                    f.write(f"    Resolution type: {resolution['resolution_type']}\n")
                    f.write(f"    All candidates: {resolution['all_candidates']}\n")
                f.write("\n")
                
                f.write(f"Final Mapping Table:\n")
                f.write(f"{'Campo Est√°ndar':<25} | {'Columna Mapeada':<30} | {'Confianza':<10}\n")
                f.write(f"{'-'*25} | {'-'*30} | {'-'*10}\n")
                
                for standard_field in self.standard_fields:
                    mapped_column = "No mapeado"
                    confidence = "0.000"
                    
                    for column_name, decision in self.user_decisions.items():
                        if decision['field_type'] == standard_field:
                            mapped_column = column_name
                            confidence = f"{decision['confidence']:.3f}"
                            break
                    
                    f.write(f"{standard_field:<25} | {mapped_column:<30} | {confidence:<10}\n")
            
            print(f"Automatic training report saved to: {report_file}")
            return report_file
            
        except Exception as e:
            print(f"Could not generate report: {e}")
            return ""
    
    def _create_transformed_csv(self) -> Dict:
        """Crea dos CSV: uno de cabecera y otro de detalle con procesamiento num√©rico autom√°tico"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # Crear DataFrame con columnas renombradas
            transformed_df = self.df.copy()
            column_mapping = {}
            
            # Crear mapeo de columnas originales a campos est√°ndar
            for column_name, decision in self.user_decisions.items():
                standard_field = decision['field_type']
                column_mapping[column_name] = standard_field
            
            # Renombrar columnas en el DataFrame
            transformed_df = transformed_df.rename(columns=column_mapping)
            
            # NUEVO: Procesar campos num√©ricos y calcular amount si es necesario
            transformed_df = self._process_numeric_fields_and_calculate_amount(transformed_df)
            
            # Determinar qu√© columnas van en header vs detail
            header_columns = []
            detail_columns = []
            
            for standard_field in self.standard_fields:
                if standard_field in transformed_df.columns:
                    # Campos de cabecera (√∫nicos por journal_entry_id)
                    if standard_field in ['journal_entry_id', 'posting_date', 'fiscal_year', 
                                        'period_number', 'prepared_by', 'entry_date', 'entry_time', 'description']:
                        header_columns.append(standard_field)
                    else:
                        # Campos de detalle (m√∫ltiples l√≠neas por journal_entry_id)
                        detail_columns.append(standard_field)
            
            # Crear CSV de cabecera (datos √∫nicos)
            if header_columns and 'journal_entry_id' in header_columns:
                header_df = transformed_df[header_columns].drop_duplicates(subset=['journal_entry_id'])
                header_file = f"automatic_training_header_{timestamp}.csv"
                header_df.to_csv(header_file, index=False, encoding='utf-8')
                print(f"Header CSV created: {header_file} ({len(header_df)} rows)")
            else:
                header_file = None
                print("No header CSV created (no journal_entry_id)")
            
            # Crear CSV de detalle (todas las l√≠neas)
            if detail_columns:
                # Incluir journal_entry_id en detalle para linking
                if 'journal_entry_id' in transformed_df.columns and 'journal_entry_id' not in detail_columns:
                    detail_columns.insert(0, 'journal_entry_id')
                
                detail_df = transformed_df[detail_columns]
                detail_file = f"automatic_training_detail_{timestamp}.csv"
                detail_df.to_csv(detail_file, index=False, encoding='utf-8')
                print(f"Detail CSV created: {detail_file} ({len(detail_df)} rows)")
            else:
                detail_file = None
                print("No detail CSV created (no detail columns mapped)")
            
            return {
                'header_file': header_file,
                'detail_file': detail_file,
                'csv_info': {
                    'header_columns': header_columns,
                    'detail_columns': detail_columns,
                    'total_standard_fields_mapped': len(self.user_decisions),
                    'unmapped_standard_fields': [f for f in self.standard_fields 
                                               if f not in [d['field_type'] for d in self.user_decisions.values()]]
                }
            }
            
        except Exception as e:
            print(f"Error creating transformed CSVs: {e}")
            return {'success': False, 'error': str(e)}
    
    def _process_numeric_fields_and_calculate_amount(self, df: pd.DataFrame) -> pd.DataFrame:
        """Procesa campos num√©ricos, limpia monedas y calcula amount si es necesario"""
        try:
            print(f"\nüí∞ PROCESSING NUMERIC FIELDS AND CALCULATING AMOUNT")
            print(f"-" * 50)
            
            # Lista de campos num√©ricos que necesitan limpieza
            numeric_fields = ['amount', 'debit_amount', 'credit_amount']
            
            # Limpiar campos num√©ricos existentes
            cleaned_fields = []
            for field in numeric_fields:
                if field in df.columns:
                    print(f"Cleaning numeric field: {field}")
                    original_samples = df[field].dropna().head(3).tolist()
                    print(f"   Original values: {original_samples}")
                    
                    df[field] = df[field].apply(self._clean_numeric_value)
                    
                    cleaned_samples = df[field].dropna().head(3).tolist()
                    print(f"   Cleaned values:  {cleaned_samples}")
                    
                    cleaned_fields.append(field)
            
            # Verificar si necesitamos calcular amount
            has_amount = 'amount' in df.columns
            has_debit = 'debit_amount' in df.columns
            has_credit = 'credit_amount' in df.columns
            
            if not has_amount and has_debit and has_credit:
                print(f"üí° CALCULATING AMOUNT: amount = debit_amount - credit_amount")
                
                # Calcular amount como debit - credit
                df['amount'] = df['debit_amount'].fillna(0) - df['credit_amount'].fillna(0)
                
                print(f"   ‚úì Amount calculated for {len(df)} rows")
                print(f"   Sample calculated amounts: {df['amount'].head(3).tolist()}")
                
            elif has_amount:
                print(f"‚úì Amount field already exists - using existing values")
            else:
                print(f"‚ö†Ô∏è Cannot calculate amount - missing debit_amount or credit_amount fields")
            
            # Mostrar resumen de limpieza
            if cleaned_fields:
                print(f"\nüìä NUMERIC FIELDS PROCESSING SUMMARY:")
                for field in cleaned_fields:
                    if field in df.columns:
                        non_null_count = df[field].notna().sum()
                        print(f"   {field}: {non_null_count} valid numeric values")
            
            return df
            
        except Exception as e:
            print(f"Error processing numeric fields: {e}")
            return df
    
    def _clean_numeric_value(self, value) -> Optional[float]:
        """Limpia un valor num√©rico eliminando texto de moneda y convirtiendo a float"""
        try:
            if pd.isna(value):
                return None
            
            # Convertir a string si no lo es
            str_value = str(value).strip()
            
            if not str_value or str_value.lower() in ['', 'nan', 'none', 'null']:
                return None
            
            # Remover espacios m√∫ltiples
            str_value = re.sub(r'\s+', ' ', str_value)
            
            # Patrones para limpiar monedas y texto
            # Ejemplos: "1000 EUR", "1,500.50 USD", "$1000", "1000‚Ç¨", "EUR 1000"
            currency_patterns = [
                r'\b[A-Z]{3}\b',        # EUR, USD, GBP, etc.
                r'[‚Ç¨$¬£¬•‚Çπ‚ÇΩ]',           # S√≠mbolos de moneda
                r'\b(euros?|dollars?|pounds?|yen)\b',  # Nombres de moneda
                r'[A-Za-z]+',          # Cualquier texto restante
            ]
            
            # Aplicar todos los patrones
            cleaned_value = str_value
            for pattern in currency_patterns:
                cleaned_value = re.sub(pattern, '', cleaned_value, flags=re.IGNORECASE)
            
            # Limpiar espacios y caracteres especiales excepto n√∫meros, puntos, comas y signos
            cleaned_value = re.sub(r'[^\d.,\-+]', '', cleaned_value)
            
            if not cleaned_value:
                return None
            
            # MEJORADO: Manejar diferentes formatos de n√∫meros incluyendo m√∫ltiples puntos/comas
            # Casos: "10.908.09", "1.234.567.89", "10,908.09", "10.908,09"
            
            # Contar puntos y comas
            dot_count = cleaned_value.count('.')
            comma_count = cleaned_value.count(',')
            
            if dot_count == 0 and comma_count == 0:
                # Solo n√∫meros enteros
                return float(cleaned_value)
                
            elif dot_count > 1 and comma_count == 0:
                # M√∫ltiples puntos: "10.908.09" ‚Üí 10908.09
                # El √∫ltimo punto es decimal si tiene 1-2 d√≠gitos despu√©s
                last_dot_pos = cleaned_value.rfind('.')
                after_last_dot = cleaned_value[last_dot_pos + 1:]
                
                if len(after_last_dot) <= 2 and after_last_dot.isdigit():
                    # √öltimo punto es decimal
                    before_decimal = cleaned_value[:last_dot_pos].replace('.', '')
                    decimal_part = after_last_dot
                    cleaned_value = before_decimal + '.' + decimal_part
                else:
                    # Todos los puntos son separadores de miles
                    cleaned_value = cleaned_value.replace('.', '')
                    
            elif comma_count > 1 and dot_count == 0:
                # M√∫ltiples comas: "10,908,09" ‚Üí 10908.09
                last_comma_pos = cleaned_value.rfind(',')
                after_last_comma = cleaned_value[last_comma_pos + 1:]
                
                if len(after_last_comma) <= 2 and after_last_comma.isdigit():
                    # √öltima coma es decimal
                    before_decimal = cleaned_value[:last_comma_pos].replace(',', '')
                    decimal_part = after_last_comma
                    cleaned_value = before_decimal + '.' + decimal_part
                else:
                    # Todas las comas son separadores de miles
                    cleaned_value = cleaned_value.replace(',', '')
                    
            elif dot_count == 1 and comma_count == 1:
                # Un punto y una coma: determinar cu√°l es decimal
                dot_pos = cleaned_value.find('.')
                comma_pos = cleaned_value.find(',')
                
                if dot_pos < comma_pos:
                    # Formato: 1.234,56 (europeo)
                    after_comma = cleaned_value[comma_pos + 1:]
                    if len(after_comma) <= 2 and after_comma.isdigit():
                        cleaned_value = cleaned_value.replace('.', '').replace(',', '.')
                    else:
                        cleaned_value = cleaned_value.replace(',', '')
                else:
                    # Formato: 1,234.56 (americano)  
                    after_dot = cleaned_value[dot_pos + 1:]
                    if len(after_dot) <= 2 and after_dot.isdigit():
                        cleaned_value = cleaned_value.replace(',', '')
                    else:
                        cleaned_value = cleaned_value.replace('.', '').replace(',', '.')
                        
            elif dot_count == 1 and comma_count == 0:
                # Solo un punto: "1234.56" o "1.234"
                dot_pos = cleaned_value.find('.')
                after_dot = cleaned_value[dot_pos + 1:]
                
                if len(after_dot) > 2:
                    # Probablemente separador de miles: "1.234" ‚Üí "1234"
                    cleaned_value = cleaned_value.replace('.', '')
                # Si tiene 1-2 d√≠gitos despu√©s, lo dejamos como decimal
                
            elif comma_count == 1 and dot_count == 0:
                # Solo una coma: "1234,56" o "1,234"
                comma_pos = cleaned_value.find(',')
                after_comma = cleaned_value[comma_pos + 1:]
                
                if len(after_comma) <= 2 and after_comma.isdigit():
                    # Probablemente decimal: "1234,56" ‚Üí "1234.56"
                    cleaned_value = cleaned_value.replace(',', '.')
                else:
                    # Probablemente separador de miles: "1,234" ‚Üí "1234"
                    cleaned_value = cleaned_value.replace(',', '')
            
            # Convertir a float
            if cleaned_value and cleaned_value not in ['.', ',', '-', '+']:
                return float(cleaned_value)
            else:
                return None
                
        except (ValueError, TypeError):
            # Si no se puede convertir, intentar extraer n√∫meros
            try:
                # Buscar patrones num√©ricos m√°s complejos
                numbers = re.findall(r'-?\d+[.,]?\d*', str(value))
                if numbers:
                    # Tomar el primer n√∫mero encontrado y limpiarlo recursivamente
                    first_num = numbers[0].replace(',', '.')
                    return float(first_num)
                return None
            except:
                return None


def run_automatic_training(csv_file: str, erp_hint: str = None) -> Dict:
    """Funci√≥n principal para ejecutar entrenamiento autom√°tico"""
    try:
        print(f"ü§ñ AUTOMATIC CONFIRMATION TRAINER")
        print(f"=" * 50)
        print(f"Starting automatic training session...")
        print(f"File: {csv_file}")
        print(f"ERP: {erp_hint or 'Auto-detect'}")
        print(f"Decision mode: AUTOMATIC (no confirmation required)")
        print(f"Quality filter: Only confidence > 0.75 accepted")
        print(f"Special rule: AMOUNT field prioritizes 'local' ALWAYS")
        print()
        
        # Crear sesi√≥n de entrenamiento autom√°tico
        session = AutomaticConfirmationTrainingSession(csv_file, erp_hint)
        
        # Inicializar
        if not session.initialize():
            return {'success': False, 'error': 'Initialization failed'}
        
        # Ejecutar entrenamiento autom√°tico
        result = session.run_automatic_training()
        
        if result['success']:
            print(f"\n‚úÖ AUTOMATIC TRAINING COMPLETED SUCCESSFULLY!")
            print(f"üìä Statistics:")
            for key, value in result['training_stats'].items():
                print(f"   ‚Ä¢ {key.replace('_', ' ').title()}: {value}")
            
            if result.get('csv_info'):
                csv_info = result['csv_info']
                if csv_info.get('header_columns'):
                    print(f"   ‚Ä¢ Header columns: {', '.join(csv_info['header_columns'])}")
                if csv_info.get('detail_columns'):
                    print(f"   ‚Ä¢ Detail columns: {', '.join(csv_info['detail_columns'])}")
            
            print(f"\nAUTOMATIC TRAINING ACHIEVEMENTS:")
            print(f"   ‚Ä¢ Automatic mappings: {result['training_stats']['automatic_mappings']}")
            print(f"   ‚Ä¢ Conflicts resolved: {result['training_stats']['conflicts_resolved']}")
            print(f"   ‚Ä¢ Amount conflicts resolved: {result['training_stats']['amount_conflicts_resolved']}")
            print(f"   ‚Ä¢ High confidence decisions: {result['training_stats']['high_confidence_mappings']}")
            print(f"   ‚Ä¢ Rejected low confidence: {result['training_stats']['rejected_low_confidence']}")
            print(f"   ‚Ä¢ Standard fields only: {len(session.standard_fields)}")
            print(f"   ‚Ä¢ LOCAL PRIORITY RULE: Active for amount conflicts")
            print(f"   ‚Ä¢ CONFIDENCE FILTER: Only mappings > {session.confidence_threshold} included")
        
        return result
        
    except Exception as e:
        print(f"Automatic training failed: {e}")
        import traceback
        traceback.print_exc()
        return {'success': False, 'error': str(e)}


def main():
    """Funci√≥n principal - COMPATIBLE con manual_confirmation_trainer.py"""
    if len(sys.argv) < 2:
        print("AUTOMATIC CONFIRMATION TRAINER")
        print("=" * 50)
        print("Training with AUTOMATIC DECISIONS - no manual confirmation required")
        print()
        print("FEATURES:")
        print("  ‚Ä¢ ALL decisions made automatically based on confidence")
        print("  ‚Ä¢ High confidence: automatic assignment")
        print("  ‚Ä¢ Confidence filter: Only mappings > 0.75 are included")
        print("  ‚Ä¢ Conflicts resolved by highest confidence")
        print("  ‚Ä¢ Special rule for 'amount': prioritizes 'local' ALWAYS")
        print("  ‚Ä¢ Automatic numeric field cleaning and amount calculation")
        print("  ‚Ä¢ Same standard fields (17 fields total)")
        print("  ‚Ä¢ Same CSV outputs as manual trainer")
        print("  ‚Ä¢ Compatible with main_global.py")
        print()
        print("STANDARD FIELDS:")
        standard_fields = [
            'journal_entry_id', 'line_number', 'description', 'line_description',
            'posting_date', 'fiscal_year', 'period_number', 'gl_account_number',
            'amount', 'debit_amount', 'credit_amount', 'debit_credit_indicator',
            'prepared_by', 'entry_date', 'entry_time', 'gl_account_name', 'vendor_id'
        ]
        for i, field in enumerate(standard_fields, 1):
            print(f"  {i:2d}. {field}")
        print()
        print("Usage:")
        print("  python automatic_confirmation_trainer.py <csv_file> [erp_hint]")
        print()
        print("Examples:")
        print("  python automatic_confirmation_trainer.py data/journal.csv")
        print("  python automatic_confirmation_trainer.py data/journal.csv SAP")
        print("  python automatic_confirmation_trainer.py data/journal.csv Oracle")
        print()
        print("OUTPUT FILES:")
        print("  ‚Ä¢ automatic_training_report_TIMESTAMP.txt")
        print("  ‚Ä¢ automatic_training_header_TIMESTAMP.csv")
        print("  ‚Ä¢ automatic_training_detail_TIMESTAMP.csv")
        print()
        print("NUMERIC PROCESSING:")
        print("  ‚Ä¢ Cleans currency symbols and text from numeric fields")
        print("  ‚Ä¢ Handles different number formats (1,234.56 vs 1.234,56)")
        print("  ‚Ä¢ Calculates amount = debit_amount - credit_amount if needed")
        return
    
    # Extraer par√°metros
    csv_file = sys.argv[1]
    erp_hint = sys.argv[2] if len(sys.argv) > 2 else None
    
    # Ejecutar entrenamiento autom√°tico
    result = run_automatic_training(csv_file, erp_hint)
    
    if not result['success']:
        print(f"‚ùå Training failed: {result.get('error')}")
        sys.exit(1)
    
    print(f"\n‚úÖ Automatic training completed successfully!")


if __name__ == "__main__":
    main()