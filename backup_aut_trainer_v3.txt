# automatic_confirmation_trainer.py - TRAINER AUTOM√ÅTICO SIN CONFIRMACI√ìN MANUAL
# BASADO EN: manual_confirmation_trainer.py pero con decisiones autom√°ticas
# REGLAS: Mayor confianza gana, excepci√≥n para 'amount' prioriza LOCAL siempre
# ENHANCED: Validaciones de balance y campos num√©ricos mejoradas

import pandas as pd
import os
import sys
import re
from typing import Dict, List, Optional, Tuple, Any
import logging
from datetime import datetime
import json
from pathlib import Path
import yaml

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AutomaticConfirmationTrainingSession:
    """Sesi√≥n de entrenamiento AUTOM√ÅTICO - sin confirmaci√≥n manual"""
    
    def __init__(self, csv_file: str, erp_hint: str = None):
        self.csv_file = csv_file
        self.erp_hint = erp_hint
        self.df = None
        self.mapper = None
        self.detector = None
        
        # MISMOS CAMPOS EST√ÅNDAR que manual trainer
        self.standard_fields = [
            'journal_entry_id', 'line_number', 'description', 'line_description',
            'posting_date', 'fiscal_year', 'period_number', 'gl_account_number',
            'amount', 'debit_amount', 'credit_amount', 'debit_credit_indicator',
            'prepared_by', 'entry_date', 'entry_time', 'gl_account_name', 'vendor_id'
        ]
        
        # Estad√≠sticas de entrenamiento autom√°tico
        self.training_stats = {
            'columns_processed': 0,
            'automatic_mappings': 0,
            'conflicts_resolved': 0,
            'amount_conflicts_resolved': 0,
            'high_confidence_mappings': 0,
            'low_confidence_mappings': 0,
            'rejected_low_confidence': 0,  # NUEVO: rechazados por baja confianza
            'unmapped_columns': 0,
            'synonyms_added': 0,
            'regex_patterns_added': 0,
            'balance_checks_performed': 0,  # NUEVO
            'unbalanced_entries': 0,  # NUEVO
            'total_debit_sum': 0.0,  # NUEVO
            'total_credit_sum': 0.0,  # NUEVO
            'zero_filled_fields': 0  # NUEVO
        }
        
        # Umbral de confianza m√≠nimo
        self.confidence_threshold = 0.75
        
        # Decisiones autom√°ticas registradas (compatible con manual trainer)
        self.user_decisions = {}  # Mantenemos el mismo nombre para compatibilidad
        self.learned_patterns = {}
        self.new_synonyms = {}
        self.new_regex_patterns = {}
        self.conflict_resolutions = {}
        
        # Archivos de configuraci√≥n (MISMOS que manual trainer)
        self.yaml_config_file = "config/pattern_learning_config.yaml"
        self.dynamic_fields_file = "config/dynamic_fields_config.yaml"
        
    def initialize(self) -> bool:
        """Inicializa la sesi√≥n de entrenamiento autom√°tico"""
        try:
            print(f"Initializing AUTOMATIC TRAINING Session...")
            print(f"File: {self.csv_file}")
            print(f"ERP Hint: {self.erp_hint or 'Auto-detect'}")
            print(f"Mode: AUTOMATIC (no manual confirmation)")
            print(f"Confidence resolution: Highest confidence wins")
            print(f"Confidence threshold: Only mappings > {self.confidence_threshold} will be included")
            print(f"Amount exception: Prioritize 'local' ALWAYS in name")
            
            # Verificar archivo
            if not os.path.exists(self.csv_file):
                print(f"File not found: {self.csv_file}")
                return False
            
            # Cargar CSV
            self.df = pd.read_csv(self.csv_file, encoding='utf-8')
            print(f"Loaded {len(self.df)} rows x {len(self.df.columns)} columns")
            
            # Importar m√≥dulos del sistema (MISMOS que manual trainer)
            try:
                from core.field_mapper import FieldMapper
                from core.field_detector import FieldDetector
                
                self.mapper = FieldMapper()
                self.detector = FieldDetector()
                print("System modules imported successfully")
                
            except ImportError as e:
                print(f"Failed to import system modules: {e}")
                return False
            
            # Cargar configuraci√≥n de patrones aprendidos
            self._load_learned_patterns()
            
            return True
            
        except Exception as e:
            print(f"Initialization failed: {e}")
            return False
    
    def _load_learned_patterns(self):
        """Carga patrones previamente aprendidos (IGUAL que manual trainer)"""
        try:
            if os.path.exists(self.yaml_config_file):
                with open(self.yaml_config_file, 'r', encoding='utf-8') as f:
                    config = yaml.safe_load(f)
                    self.learned_patterns = config.get('learned_patterns', {})
                    print(f"Loaded {len(self.learned_patterns)} learned patterns")
            else:
                print("No previous learned patterns found")
        except Exception as e:
            print(f"Could not load learned patterns: {e}")
            self.learned_patterns = {}
    
    def run_automatic_training(self) -> Dict:
        """Ejecuta el entrenamiento autom√°tico SIN confirmaci√≥n manual"""
        try:
            print(f"\nStarting AUTOMATIC FIELD TRAINING...")
            print(f"=" * 55)
            print(f"All decisions will be made automatically based on confidence")
            print(f"Special rule for 'amount': prioritize 'local' columns ALWAYS")
            print(f"Confidence threshold: {self.confidence_threshold} (only mappings above this will be included)")
            
            # An√°lisis inicial del DataFrame (IGUAL que manual trainer)
            print(f"CSV Columns ({len(self.df.columns)}):")
            for i, col in enumerate(self.df.columns, 1):
                print(f"  {i:2d}. {col}")
            
            # Detectar mappings autom√°ticamente usando find_field_mapping
            print(f"\nFIELD MAPPING RESULTS:")
            field_mappings = {}
            unmapped_columns = []
            
            for column in self.df.columns:
                sample_data = self.df[column].dropna().head(100)  # Proporcionar datos de muestra
                mapping_result = self.mapper.find_field_mapping(column, self.erp_hint, sample_data)
                
                if mapping_result:
                    field_type, confidence = mapping_result
                    field_mappings[column] = {
                        'field_type': field_type,
                        'confidence': confidence
                    }
                else:
                    unmapped_columns.append(column)
            
            print(f"  Successful mappings: {len(field_mappings)}")
            print(f"  Failed mappings: {len(unmapped_columns)}")
            
            # Procesar mapeos autom√°ticamente
            final_mappings = {}
            for column_name, mapping_info in field_mappings.items():
                field_type = mapping_info['field_type']
                confidence = mapping_info['confidence']
                
                self.training_stats['columns_processed'] += 1
                
                # FILTRO DE CONFIANZA: Solo incluir mapeos por encima del umbral
                if confidence < self.confidence_threshold:
                    print(f"  REJECTED: '{column_name}' -> {field_type} (confidence: {confidence:.3f} < {self.confidence_threshold})")
                    self.training_stats['rejected_low_confidence'] += 1
                    continue
                
                # Verificar conflictos (m√∫ltiples columnas para el mismo campo)
                existing_mappings = [col for col, info in final_mappings.items() if info['field_type'] == field_type]
                
                if existing_mappings:
                    # CONFLICTO DETECTADO - resolver autom√°ticamente
                    print(f"  CONFLICT for '{field_type}': '{column_name}' vs {existing_mappings}")
                    
                    # Resolver conflicto autom√°ticamente
                    winner_info = self._resolve_conflict_automatically(
                        field_type, 
                        [(column_name, confidence)] + [(col, final_mappings[col]['confidence']) for col in existing_mappings]
                    )
                    
                    if winner_info:
                        winner_column, winner_confidence, resolution_type = winner_info
                        
                        # Remover perdedores
                        for loser_col in existing_mappings:
                            if loser_col in final_mappings:
                                del final_mappings[loser_col]
                        
                        # Agregar ganador
                        final_mappings[winner_column] = {
                            'field_type': field_type,
                            'confidence': winner_confidence,
                            'resolution_type': resolution_type
                        }
                        
                        self.conflict_resolutions[field_type] = {
                            'winner': winner_column,
                            'resolution_type': resolution_type,
                            'all_candidates': [column_name] + existing_mappings
                        }
                        
                        if field_type == 'amount':
                            self.training_stats['amount_conflicts_resolved'] += 1
                        else:
                            self.training_stats['conflicts_resolved'] += 1
                        
                        print(f"    RESOLVED: '{winner_column}' wins ({resolution_type})")
                    
                else:
                    # Sin conflicto - agregar directamente
                    final_mappings[column_name] = {
                        'field_type': field_type,
                        'confidence': confidence,
                        'resolution_type': 'no_conflict'
                    }
                    print(f"  ACCEPTED: '{column_name}' -> {field_type} (confidence: {confidence:.3f})")
            
            # Actualizar user_decisions para compatibilidad
            self._update_user_decisions_from_mappings(final_mappings)
            
            # Finalizar entrenamiento
            result = self._finalize_automatic_training()
            
            return result
            
        except Exception as e:
            import traceback
            traceback.print_exc()
            return {'success': False, 'error': str(e)}
    
    def _resolve_conflict_automatically(self, field_type: str, candidates: List[Tuple[str, float]]) -> Optional[Tuple[str, float, str]]:
        """Resuelve conflictos autom√°ticamente usando reglas predefinidas"""
        
        if not candidates:
            return None
        
        print(f"    RESOLVING CONFLICT for '{field_type}':")
        for column_name, confidence in candidates:
            print(f"      Candidate: '{column_name}' (confidence: {confidence:.3f})")
        
        # REGLA ESPECIAL PARA AMOUNT: Priorizar columnas con 'local' en el nombre
        if field_type == 'amount':
            return self._resolve_amount_conflict_with_local_priority(candidates)
        
        # REGLA GENERAL: Mayor confianza gana
        candidates_sorted = sorted(candidates, key=lambda x: x[1], reverse=True)
        winner_column, winner_confidence = candidates_sorted[0]
        
        print(f"    GENERAL RULE: '{winner_column}' has highest confidence ({winner_confidence:.3f})")
        return (winner_column, winner_confidence, 'highest_confidence')
    
    def _resolve_amount_conflict_with_local_priority(self, candidates: List[Tuple[str, float]]) -> Tuple[str, float, str]:
        """Resuelve conflictos de amount priorizando 'local' en el nombre"""
        
        print(f"    AMOUNT SPECIAL RULE: Checking for 'local' priority...")
        
        # PASO 1: Buscar candidatos que contengan palabras prioritarias
        priority_keywords = ['local', 'loc', 'domestico', 'domestic']
        priority_candidates = []
        
        for column_name, confidence in candidates:
            column_lower = column_name.lower()
            for keyword in priority_keywords:
                if keyword in column_lower:
                    priority_candidates.append((column_name, confidence, f'amount_priority_{keyword}'))
                    print(f"    FOUND PRIORITY CANDIDATE: '{column_name}' (contains '{keyword}')")
                    break
        
        # Si hay candidatos prioritarios, elegir el de mayor confianza entre ellos
        if priority_candidates:
            best_priority = max(priority_candidates, key=lambda x: x[1])
            print(f"    PRIORITY RULE: '{best_priority[0]}' contains '{best_priority[2].split('_')[-1]}'")
            return best_priority
        
        # PASO 3: Si no hay candidatos prioritarios, usar regla general (mayor confianza)
        candidates_sorted = sorted(candidates, key=lambda x: x[1], reverse=True)
        winner_column, winner_confidence = candidates_sorted[0]
        
        print(f"    FALLBACK RULE: '{winner_column}' has highest confidence ({winner_confidence:.3f})")
        return (winner_column, winner_confidence, 'amount_highest_confidence')
    
    def _update_user_decisions_from_mappings(self, final_mappings: Dict):
        """Actualiza user_decisions basado en mapeos finales (compatible con manual trainer)"""
        for column_name, mapping_info in final_mappings.items():
            field_type = mapping_info['field_type']
            confidence = mapping_info['confidence']
            resolution_type = mapping_info['resolution_type']
            
            # Determinar tipo de decisi√≥n autom√°tica
            if resolution_type == 'no_conflict':
                decision_type = 'automatic_no_conflict'
            else:
                decision_type = f'automatic_{resolution_type}'
            
            self.user_decisions[column_name] = {
                'field_type': field_type,
                'confidence': confidence,
                'decision_type': decision_type,
                'resolution_type': resolution_type
            }
            
            # Actualizar estad√≠sticas
            if confidence > 0.8:
                self.training_stats['high_confidence_mappings'] += 1
            else:
                self.training_stats['low_confidence_mappings'] += 1
                
            self.training_stats['automatic_mappings'] += 1
    
    def _finalize_automatic_training(self) -> Dict:
        """Finaliza el entrenamiento autom√°tico y genera resultados (FORMATO COMPATIBLE)"""
        try:
            print(f"\nAUTOMATIC TRAINING FINALIZATION")
            print(f"=" * 40)
            
            # Generar reporte
            report_file = self._generate_training_report()
            
            # Crear CSV transformado con validaciones
            csv_result = self._create_transformed_csv()
            
            # Preparar resultado final
            result = {
                'success': True,
                'training_stats': self.training_stats,
                'user_decisions': self.user_decisions,
                'conflict_resolutions': self.conflict_resolutions,
                'report_file': report_file,
                **csv_result
            }
            
            return result
            
        except Exception as e:
            import traceback
            traceback.print_exc()
            return {'success': False, 'error': str(e)}
    
    def _generate_training_report(self) -> str:
        """Genera reporte de entrenamiento autom√°tico"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            report_file = f"automatic_training_report_{timestamp}.txt"
            
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(f"AUTOMATIC FIELD TRAINING SESSION REPORT\n")
                f.write(f"=" * 50 + "\n\n")
                
                f.write(f"Session Information:\n")
                f.write(f"  CSV File: {self.csv_file}\n")
                f.write(f"  ERP Hint: {self.erp_hint or 'Auto-detect'}\n")
                f.write(f"  Standard Fields: {len(self.standard_fields)}\n")
                f.write(f"  Mode: AUTOMATIC (no manual confirmation)\n")
                f.write(f"  Timestamp: {datetime.now().isoformat()}\n\n")
                
                f.write(f"Training Statistics:\n")
                for key, value in self.training_stats.items():
                    f.write(f"  {key.replace('_', ' ').title()}: {value}\n")
                f.write("\n")
                
                f.write(f"Automatic Decisions:\n")
                for column, decision in self.user_decisions.items():
                    f.write(f"  {column}: {decision['field_type']} ")
                    f.write(f"(confidence: {decision['confidence']:.3f}, ")
                    f.write(f"type: {decision['decision_type']})\n")
                f.write("\n")
                
                f.write(f"Conflict Resolutions:\n")
                for field_type, resolution in self.conflict_resolutions.items():
                    f.write(f"  {field_type}:\n")
                    f.write(f"    Winner: {resolution['winner']}\n")
                    f.write(f"    Resolution type: {resolution['resolution_type']}\n")
                    f.write(f"    All candidates: {resolution['all_candidates']}\n")
                f.write("\n")
                
                f.write(f"Final Mapping Table:\n")
                f.write(f"{'Campo Est√°ndar':<25} | {'Columna Mapeada':<30} | {'Confianza':<10}\n")
                f.write(f"{'-'*25} | {'-'*30} | {'-'*10}\n")
                
                for standard_field in self.standard_fields:
                    mapped_column = "No mapeado"
                    confidence = "0.000"
                    
                    for column_name, decision in self.user_decisions.items():
                        if decision['field_type'] == standard_field:
                            mapped_column = column_name
                            confidence = f"{decision['confidence']:.3f}"
                            break
                  
                    f.write(f"{standard_field:<25} | {mapped_column:<30} | {confidence:<10}\n")
            
            print(f"Automatic training report saved to: {report_file}")
            return report_file
            
        except Exception as e:
            print(f"Could not generate report: {e}")
            return ""
    
    def _create_transformed_csv(self) -> Dict:
        """Crea dos CSV: uno de cabecera y otro de detalle con procesamiento num√©rico autom√°tico"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # Crear DataFrame con columnas renombradas
            transformed_df = self.df.copy()
            column_mapping = {}
            
            # Crear mapeo de columnas originales a campos est√°ndar
            for column_name, decision in self.user_decisions.items():
                standard_field = decision['field_type']
                column_mapping[column_name] = standard_field
            
            # Renombrar columnas en el DataFrame
            transformed_df = transformed_df.rename(columns=column_mapping)
            
            # NUEVO: Procesar campos num√©ricos y calcular amount si es necesario
            transformed_df = self._process_numeric_fields_and_calculate_amount(transformed_df)
            
            # NUEVO: Realizar validaciones de balance por asiento
            balance_report = self._perform_balance_validations(transformed_df)
            
            # Determinar qu√© columnas van en header vs detail
            header_columns = []
            detail_columns = []
            
            for standard_field in self.standard_fields:
                if standard_field in transformed_df.columns:
                    # Campos de cabecera (√∫nicos por journal_entry_id)
                    if standard_field in ['journal_entry_id', 'posting_date', 'fiscal_year', 
                                        'period_number', 'prepared_by', 'entry_date', 'entry_time', 'description']:
                        header_columns.append(standard_field)
                    else:
                        # Campos de detalle (m√∫ltiples l√≠neas por journal_entry_id)
                        detail_columns.append(standard_field)
            
            # NUEVO: Ordenar por journal_entry_id de manera ascendente
            if 'journal_entry_id' in transformed_df.columns:
                transformed_df = transformed_df.sort_values('journal_entry_id', ascending=True)
                print(f"‚úì Data sorted by journal_entry_id in ascending order")
            
            # Crear CSV de cabecera (datos √∫nicos)
            if header_columns and 'journal_entry_id' in header_columns:
                header_df = transformed_df[header_columns].drop_duplicates(subset=['journal_entry_id'])
                # Ordenar header por journal_entry_id
                header_df = header_df.sort_values('journal_entry_id', ascending=True)
                header_file = f"automatic_training_header_{timestamp}.csv"
                header_df.to_csv(header_file, index=False, encoding='utf-8')
                print(f"Header CSV created: {header_file} ({len(header_df)} rows)")
            else:
                header_file = None
                print("No header CSV created (no journal_entry_id)")
            
            # Crear CSV de detalle (todas las l√≠neas)
            if detail_columns:
                # Incluir journal_entry_id en detalle para linking
                if 'journal_entry_id' in transformed_df.columns and 'journal_entry_id' not in detail_columns:
                    detail_columns.insert(0, 'journal_entry_id')
                
                detail_df = transformed_df[detail_columns]
                # Ordenar detail por journal_entry_id
                if 'journal_entry_id' in detail_df.columns:
                    detail_df = detail_df.sort_values('journal_entry_id', ascending=True)
                detail_file = f"automatic_training_detail_{timestamp}.csv"
                detail_df.to_csv(detail_file, index=False, encoding='utf-8')
                print(f"Detail CSV created: {detail_file} ({len(detail_df)} rows)")
            else:
                detail_file = None
                print("No detail CSV created (no detail columns mapped)")
            
            return {
                'header_file': header_file,
                'detail_file': detail_file,
                'balance_report': balance_report,
                'csv_info': {
                    'header_columns': header_columns,
                    'detail_columns': detail_columns,
                    'total_standard_fields_mapped': len(self.user_decisions),
                    'unmapped_standard_fields': [f for f in self.standard_fields 
                                               if f not in [d['field_type'] for d in self.user_decisions.values()]]
                }
            }
            
        except Exception as e:
            print(f"Error creating transformed CSVs: {e}")
            return {'success': False, 'error': str(e)}
    
    def _process_numeric_fields_and_calculate_amount(self, df: pd.DataFrame) -> pd.DataFrame:
        """Procesa campos num√©ricos, limpia monedas y calcula amount si es necesario"""
        try:
            print(f"\nüí∞ PROCESSING NUMERIC FIELDS AND CALCULATING AMOUNT")
            print(f"-" * 50)
            
            # Lista de campos num√©ricos que necesitan limpieza
            numeric_fields = ['amount', 'debit_amount', 'credit_amount']
            
            # Limpiar campos num√©ricos existentes y RELLENAR CON CEROS
            cleaned_fields = []
            for field in numeric_fields:
                if field in df.columns:
                    print(f"Cleaning numeric field: {field}")
                    original_samples = df[field].dropna().head(3).tolist()
                    print(f"   Original values: {original_samples}")
                    
                    # Aplicar limpieza que ya incluye fillna con 0
                    df[field] = df[field].apply(self._clean_numeric_value_with_zero_fill)
                    
                    cleaned_samples = df[field].head(3).tolist()
                    print(f"   Cleaned values:  {cleaned_samples}")
                    
                    # Contar cu√°ntos valores se rellenaron con cero
                    zero_count = (df[field] == 0.0).sum()
                    self.training_stats['zero_filled_fields'] += zero_count
                    print(f"   Zero-filled count: {zero_count}")
                    
                    cleaned_fields.append(field)
            
            # Verificar si necesitamos calcular amount
            has_amount = 'amount' in df.columns
            has_debit = 'debit_amount' in df.columns
            has_credit = 'credit_amount' in df.columns
            
            if not has_amount and has_debit and has_credit:
                print(f"üí° CALCULATING AMOUNT: amount = debit_amount - credit_amount")
                
                # Calcular amount como debit - credit (ya con ceros incluidos)
                df['amount'] = df['debit_amount'] - df['credit_amount']
                
                print(f"   ‚úì Amount calculated for {len(df)} rows")
                print(f"   Sample calculated amounts: {df['amount'].head(3).tolist()}")
                
            elif has_amount:
                print(f"‚úì Amount field already exists - using existing values")
            else:
                print(f"‚ö†Ô∏è Cannot calculate amount - missing debit_amount or credit_amount fields")
            
            # Mostrar resumen de limpieza
            if cleaned_fields:
                print(f"\nüìä NUMERIC FIELDS PROCESSING SUMMARY:")
                for field in cleaned_fields:
                    if field in df.columns:
                        non_null_count = df[field].notna().sum()
                        zero_count = (df[field] == 0.0).sum()
                        print(f"   {field}: {non_null_count} valid values, {zero_count} zeros")
            
            return df
            
        except Exception as e:
            print(f"Error processing numeric fields: {e}")
            return df
    
    def _clean_numeric_value_with_zero_fill(self, value) -> float:
        """Limpia un valor num√©rico eliminando texto de moneda y convirtiendo a float, RELLENANDO CON 0"""
        try:
            if pd.isna(value) or value == '' or value is None:
                return 0.0  # CAMBIO PRINCIPAL: Devolver 0.0 en lugar de None
            
            # Convertir a string si no lo es
            str_value = str(value).strip()
            
            if not str_value or str_value.lower() in ['', 'nan', 'none', 'null']:
                return 0.0  # CAMBIO PRINCIPAL: Devolver 0.0 en lugar de None
            
            # Remover espacios m√∫ltiples
            str_value = re.sub(r'\s+', ' ', str_value)
            
            # Patrones para limpiar monedas y texto
            # Ejemplos: "1000 EUR", "1,500.50 USD", "$1000", "1000‚Ç¨", "EUR 1000"
            currency_patterns = [
                r'\b[A-Z]{3}\b',        # EUR, USD, GBP, etc.
                r'[$‚Ç¨¬£¬•‚Çπ‚ÇΩ¬¢]',          # S√≠mbolos de moneda
                r'\b(USD|EUR|GBP|JPY|CAD|AUD|CHF|CNY|SEK|NOK|DKK|PLN|CZK|HUF|BGN|RON|HRK|RUB|TRY|BRL|MXN|ARS|CLP|PEN|COP|UYU|PYG|BOB|VEF|GYD|SRD|TTD|JMD|BBD|BSD|KYD|XCD|AWG|ANG|CUP|DOP|GTQ|HNL|NIO|CRC|PAB|BZD|SVC|HTG)\b',  # C√≥digos ISO comunes
                r'\b(DOLLAR|EURO|POUND|YEN|PESO|REAL|FRANC|KRONA|KRONE|ZLOTY|FORINT|LEU|LIRA|RUBLE|YUAN|RUPEE)\b',  # Nombres de monedas en ingl√©s
                r'\b(DOLAR|EUROS|LIBRA|YENES|PESOS|REALES|FRANCOS|CORONAS|RUBLOS|YUANES|RUPIAS)\b'  # Nombres en espa√±ol
            ]
            
            # Aplicar limpieza de monedas
            cleaned_value = str_value
            for pattern in currency_patterns:
                cleaned_value = re.sub(pattern, '', cleaned_value, flags=re.IGNORECASE)
            
            # Limpiar caracteres no num√©ricos excepto punto, coma y signo menos
            cleaned_value = re.sub(r'[^0-9.,-]', '', cleaned_value)
            
            # Manejar signos negativos
            is_negative = cleaned_value.count('-') % 2 == 1  # Impar = negativo
            cleaned_value = cleaned_value.replace('-', '')
            
            if not cleaned_value or not any(c.isdigit() for c in cleaned_value):
                return 0.0  # CAMBIO PRINCIPAL: Devolver 0.0 en lugar de None
            
            # Detectar formato de n√∫mero mejorado
            if '.' in cleaned_value and ',' in cleaned_value:
                # Ambos presentes: detectar cu√°l es el decimal
                last_dot = cleaned_value.rfind('.')
                last_comma = cleaned_value.rfind(',')
                
                if last_dot > last_comma:
                    # Punto como decimal: "1,234.56"
                    cleaned_value = cleaned_value.replace(',', '')
                else:
                    # Coma como decimal: "1.234,56"
                    cleaned_value = cleaned_value.replace('.', '').replace(',', '.')
            
            elif ',' in cleaned_value:
                # Solo comas
                comma_parts = cleaned_value.split(',')
                if len(comma_parts) == 2 and len(comma_parts[1]) <= 3:
                    # Probablemente decimal: "1234,56"
                    cleaned_value = cleaned_value.replace(',', '.')
                else:
                    # Probablemente separador de miles: "1,234"
                    cleaned_value = cleaned_value.replace(',', '')
            
            elif '.' in cleaned_value:
                # Solo puntos - L√ìGICA MEJORADA
                dot_parts = cleaned_value.split('.')
                if len(dot_parts) >= 2:
                    last_part = dot_parts[-1]
                    # Si la √∫ltima parte tiene 1-2 d√≠gitos, probablemente es decimal
                    if len(last_part) <= 2 and last_part.isdigit():
                        # Formato europeo: "229.006.45" -> separadores de miles + decimal
                        # Unir todas las partes excepto la √∫ltima como entero
                        integer_part = ''.join(dot_parts[:-1])
                        decimal_part = last_part
                        cleaned_value = f"{integer_part}.{decimal_part}"
                    else:
                        # Todos los puntos son separadores de miles: "1.234.567"
                        cleaned_value = cleaned_value.replace('.', '')
            
            
            # Convertir a float
            if cleaned_value and cleaned_value not in ['.', ',', '-', '+']:
                result = float(cleaned_value)
                return -result if is_negative else result
            else:
                return 0.0  # CAMBIO PRINCIPAL: Devolver 0.0 en lugar de None
                
        except (ValueError, TypeError):
            # Si no se puede convertir, intentar extraer n√∫meros
            try:
                # Buscar patrones num√©ricos m√°s complejos
                numbers = re.findall(r'-?\d+[.,]?\d*', str(value))
                if numbers:
                    # Tomar el primer n√∫mero encontrado y limpiarlo recursivamente
                    first_num = numbers[0].replace(',', '.')
                    return float(first_num)
                return 0.0  # CAMBIO PRINCIPAL: Devolver 0.0 en lugar de None
            except:
                return 0.0  # CAMBIO PRINCIPAL: Devolver 0.0 en lugar de None

    def _perform_balance_validations(self, df: pd.DataFrame) -> Dict:
        """Realiza validaciones de balance por asiento y en total"""
        try:
            print(f"\n‚öñÔ∏è PERFORMING BALANCE VALIDATIONS")
            print(f"-" * 40)
            
            balance_report = {
                'total_debit_sum': 0.0,
                'total_credit_sum': 0.0,
                'total_balance_difference': 0.0,
                'is_balanced': False,
                'entry_balance_check': [],
                'unbalanced_entries': [],
                'entries_count': 0,
                'balanced_entries_count': 0
            }
            
            has_debit = 'debit_amount' in df.columns
            has_credit = 'credit_amount' in df.columns
            has_journal_id = 'journal_entry_id' in df.columns
            
            if not (has_debit and has_credit):
                print("‚ö†Ô∏è Cannot perform balance validation - missing debit_amount or credit_amount")
                return balance_report
            
            # Calcular totales generales
            total_debit = df['debit_amount'].sum()
            total_credit = df['credit_amount'].sum()
            total_difference = total_debit - total_credit
            
            balance_report['total_debit_sum'] = total_debit
            balance_report['total_credit_sum'] = total_credit
            balance_report['total_balance_difference'] = total_difference
            balance_report['is_balanced'] = abs(total_difference) < 0.01  # Tolerancia para decimales
            
            self.training_stats['total_debit_sum'] = total_debit
            self.training_stats['total_credit_sum'] = total_credit
            self.training_stats['balance_checks_performed'] = 1
            
            print(f"üìä TOTAL BALANCE CHECK:")
            print(f"   Total Debit:  {total_debit:,.2f}")
            print(f"   Total Credit: {total_credit:,.2f}")
            print(f"   Difference:   {total_difference:,.2f}")
            print(f"   Is Balanced:  {'‚úì YES' if balance_report['is_balanced'] else '‚úó NO'}")
            
            # Validaci√≥n por asiento si existe journal_entry_id
            if has_journal_id:
                print(f"\nüìã ENTRY-LEVEL BALANCE CHECK:")
                
                # Agrupar por journal_entry_id
                grouped = df.groupby('journal_entry_id').agg({
                    'debit_amount': 'sum',
                    'credit_amount': 'sum'
                }).reset_index()
                
                # Calcular diferencia por asiento
                grouped['balance_difference'] = grouped['debit_amount'] - grouped['credit_amount']
                grouped['is_balanced'] = abs(grouped['balance_difference']) < 0.01
                
                balance_report['entries_count'] = len(grouped)
                balance_report['balanced_entries_count'] = grouped['is_balanced'].sum()
                
                # Identificar asientos desbalanceados
                unbalanced = grouped[~grouped['is_balanced']]
                balance_report['unbalanced_entries'] = unbalanced.to_dict('records')
                self.training_stats['unbalanced_entries'] = len(unbalanced)
                
                print(f"   Total Entries: {len(grouped)}")
                print(f"   Balanced:      {balance_report['balanced_entries_count']}")
                print(f"   Unbalanced:    {len(unbalanced)}")
                
                if len(unbalanced) > 0:
                    print(f"\n‚ö†Ô∏è UNBALANCED ENTRIES DETECTED:")
                    for _, entry in unbalanced.head(10).iterrows():  # Mostrar primeros 10
                        print(f"   Entry {entry['journal_entry_id']}: Debit {entry['debit_amount']:,.2f} - Credit {entry['credit_amount']:,.2f} = {entry['balance_difference']:,.2f}")
                    
                    if len(unbalanced) > 10:
                        print(f"   ... and {len(unbalanced) - 10} more unbalanced entries")
                else:
                    print(f"   ‚úì All entries are balanced!")
                
                # Guardar detalles para el reporte
                balance_report['entry_balance_check'] = grouped.to_dict('records')
            
            else:
                print("   No journal_entry_id found - skipping entry-level validation")
            
            return balance_report
            
        except Exception as e:
            print(f"Error performing balance validations: {e}")
            return balance_report


def run_automatic_training(csv_file: str, erp_hint: str = None) -> Dict:
    """Funci√≥n principal para ejecutar entrenamiento autom√°tico"""
    try:
        print(f"ü§ñ AUTOMATIC CONFIRMATION TRAINER")
        print(f"=" * 50)
        print(f"Starting automatic training session...")
        print(f"File: {csv_file}")
        print(f"ERP: {erp_hint or 'Auto-detect'}")
        print(f"Decision mode: AUTOMATIC (no confirmation required)")
        print(f"Quality filter: Only confidence > 0.75 accepted")
        print(f"Special rule: AMOUNT field prioritizes 'local' ALWAYS")
        print(f"Enhancement: Zero-fill empty numeric fields & balance validation")
        print()
        
        # Crear sesi√≥n de entrenamiento autom√°tico
        session = AutomaticConfirmationTrainingSession(csv_file, erp_hint)
        
        # Inicializar
        if not session.initialize():
            return {'success': False, 'error': 'Initialization failed'}
        
        # Ejecutar entrenamiento autom√°tico
        result = session.run_automatic_training()
        
        if result['success']:
            print(f"\n‚úÖ AUTOMATIC TRAINING COMPLETED SUCCESSFULLY!")
            print(f"üìä Statistics:")
            for key, value in result['training_stats'].items():
                print(f"   ‚Ä¢ {key.replace('_', ' ').title()}: {value}")
            
            if result.get('csv_info'):
                csv_info = result['csv_info']
                if csv_info.get('header_columns'):
                    print(f"   ‚Ä¢ Header columns: {', '.join(csv_info['header_columns'])}")
                if csv_info.get('detail_columns'):
                    print(f"   ‚Ä¢ Detail columns: {', '.join(csv_info['detail_columns'])}")
            
            # Mostrar informaci√≥n de balance si est√° disponible
            if result.get('balance_report'):
                balance = result['balance_report']
                print(f"\n‚öñÔ∏è BALANCE VALIDATION RESULTS:")
                print(f"   ‚Ä¢ Total Balance: {'‚úì BALANCED' if balance['is_balanced'] else '‚úó UNBALANCED'}")
                print(f"   ‚Ä¢ Total Debit: {balance['total_debit_sum']:,.2f}")
                print(f"   ‚Ä¢ Total Credit: {balance['total_credit_sum']:,.2f}")
                if balance['entries_count'] > 0:
                    print(f"   ‚Ä¢ Entries Balanced: {balance['balanced_entries_count']}/{balance['entries_count']}")
                    print(f"   ‚Ä¢ Unbalanced Entries: {len(balance.get('unbalanced_entries', []))}")
            
            print(f"\nAUTOMATIC TRAINING ACHIEVEMENTS:")
            print(f"   ‚Ä¢ Automatic mappings: {result['training_stats']['automatic_mappings']}")
            print(f"   ‚Ä¢ Conflicts resolved: {result['training_stats']['conflicts_resolved']}")
            print(f"   ‚Ä¢ Amount conflicts resolved: {result['training_stats']['amount_conflicts_resolved']}")
            print(f"   ‚Ä¢ High confidence decisions: {result['training_stats']['high_confidence_mappings']}")
            print(f"   ‚Ä¢ Rejected low confidence: {result['training_stats']['rejected_low_confidence']}")
            print(f"   ‚Ä¢ Zero-filled fields: {result['training_stats']['zero_filled_fields']}")
            print(f"   ‚Ä¢ Standard fields only: {len(session.standard_fields)}")
            print(f"   ‚Ä¢ LOCAL PRIORITY RULE: Active for amount conflicts")
            print(f"   ‚Ä¢ CONFIDENCE FILTER: Only mappings > {session.confidence_threshold} included")
            print(f"   ‚Ä¢ ORDER BY: journal_entry_id ASC applied to both header and detail")
        
        return result
        
    except Exception as e:
        print(f"Automatic training failed: {e}")
        import traceback
        traceback.print_exc()
        return {'success': False, 'error': str(e)}


def main():
    """Funci√≥n principal - COMPATIBLE con manual_confirmation_trainer.py"""
    if len(sys.argv) < 2:
        print("AUTOMATIC CONFIRMATION TRAINER - ENHANCED")
        print("=" * 50)
        print("Training with AUTOMATIC DECISIONS - no manual confirmation required")
        print()
        print("FEATURES:")
        print("  ‚Ä¢ ALL decisions made automatically based on confidence")
        print("  ‚Ä¢ High confidence: automatic assignment")
        print("  ‚Ä¢ Confidence filter: Only mappings > 0.75 are included")
        print("  ‚Ä¢ Conflicts resolved by highest confidence")
        print("  ‚Ä¢ Special rule for 'amount': prioritizes 'local' ALWAYS")
        print("  ‚Ä¢ Automatic numeric field cleaning and amount calculation")
        print("  ‚Ä¢ Zero-fill empty numeric fields (debit, credit, amount)")
        print("  ‚Ä¢ Balance validation by entry and total")
        print("  ‚Ä¢ Ordered output by journal_entry_id (ascending)")
        print("  ‚Ä¢ Same standard fields (17 fields total)")
        print("  ‚Ä¢ Same CSV outputs as manual trainer")
        print("  ‚Ä¢ Compatible with main_global.py")
        print()
        print("STANDARD FIELDS:")
        standard_fields = [
            'journal_entry_id', 'line_number', 'description', 'line_description',
            'posting_date', 'fiscal_year', 'period_number', 'gl_account_number',
            'amount', 'debit_amount', 'credit_amount', 'debit_credit_indicator',
            'prepared_by', 'entry_date', 'entry_time', 'gl_account_name', 'vendor_id'
        ]
        for i, field in enumerate(standard_fields, 1):
            print(f"  {i:2d}. {field}")
        print()
        print("Usage:")
        print("  python automatic_confirmation_trainer.py <csv_file> [erp_hint]")
        print()
        print("Examples:")
        print("  python automatic_confirmation_trainer.py data/journal.csv")
        print("  python automatic_confirmation_trainer.py data/journal.csv SAP")
        print("  python automatic_confirmation_trainer.py data/journal.csv Oracle")
        print()
        print("OUTPUT FILES:")
        print("  ‚Ä¢ automatic_training_report_TIMESTAMP.txt")
        print("  ‚Ä¢ automatic_training_header_TIMESTAMP.csv (ordered by journal_entry_id)")
        print("  ‚Ä¢ automatic_training_detail_TIMESTAMP.csv (ordered by journal_entry_id)")
        print()
        print("NUMERIC PROCESSING:")
        print("  ‚Ä¢ Cleans currency symbols and text from numeric fields")
        print("  ‚Ä¢ Handles different number formats (1,234.56 vs 1.234,56)")
        print("  ‚Ä¢ Fills empty numeric fields with 0.0 (NEW)")
        print("  ‚Ä¢ Calculates amount = debit_amount - credit_amount if needed")
        print("  ‚Ä¢ Validates total balance: debit_sum == credit_sum")
        print("  ‚Ä¢ Checks balance by journal entry: debit - credit = 0 per entry")
        print("  ‚Ä¢ Reports unbalanced entries in detail")
        return
    
    # Extraer par√°metros
    csv_file = sys.argv[1]
    erp_hint = sys.argv[2] if len(sys.argv) > 2 else None
    
    # Ejecutar entrenamiento autom√°tico
    result = run_automatic_training(csv_file, erp_hint)
    
    if not result['success']:
        print(f"‚ùå Training failed: {result.get('error')}")
        sys.exit(1)
    
    print(f"\n‚úÖ Automatic training completed successfully!")


if __name__ == "__main__":
    main()