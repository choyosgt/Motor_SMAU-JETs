# automatic_confirmation_trainer.py - TRAINER AUTOMÁTICO SIN CONFIRMACIÓN MANUAL
# BASADO EN: manual_confirmation_trainer.py pero con decisiones automáticas
# REGLAS: Mayor confianza gana, excepción para 'amount' prioriza LOCAL siempre
# ENHANCED: Validaciones de balance y campos numéricos mejoradas

import pandas as pd
import os
import sys
import re
from typing import Dict, List, Optional, Tuple, Any
import logging
from datetime import datetime
import json
from pathlib import Path
import yaml

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AutomaticConfirmationTrainingSession:
    """Sesión de entrenamiento AUTOMÁTICO - sin confirmación manual"""
    
    def __init__(self, csv_file: str, erp_hint: str = None):
        self.csv_file = csv_file
        self.erp_hint = erp_hint
        self.df = None
        self.mapper = None
        self.detector = None
        
        # MISMOS CAMPOS ESTÁNDAR que manual trainer
        self.standard_fields = [
            'journal_entry_id', 'line_number', 'description', 'line_description',
            'posting_date', 'fiscal_year', 'period_number', 'gl_account_number',
            'amount', 'debit_amount', 'credit_amount', 'debit_credit_indicator',
            'prepared_by', 'entry_date', 'entry_time', 'gl_account_name', 'vendor_id'
        ]
        
        # Estadísticas de entrenamiento automático
        self.training_stats = {
            'columns_processed': 0,
            'automatic_mappings': 0,
            'conflicts_resolved': 0,
            'amount_conflicts_resolved': 0,
            'high_confidence_mappings': 0,
            'low_confidence_mappings': 0,
            'rejected_low_confidence': 0,  # NUEVO: rechazados por baja confianza
            'unmapped_columns': 0,
            'synonyms_added': 0,
            'regex_patterns_added': 0,
            'balance_checks_performed': 0,  # NUEVO
            'unbalanced_entries': 0,  # NUEVO
            'total_debit_sum': 0.0,  # NUEVO
            'total_credit_sum': 0.0,  # NUEVO
            'zero_filled_fields': 0  # NUEVO
        }
        
        # Umbral de confianza mínimo
        self.confidence_threshold = 0.75
        
        # Decisiones automáticas registradas (compatible con manual trainer)
        self.user_decisions = {}  # Mantenemos el mismo nombre para compatibilidad
        self.learned_patterns = {}
        self.new_synonyms = {}
        self.new_regex_patterns = {}
        self.conflict_resolutions = {}
        
        # Archivos de configuración (MISMOS que manual trainer)
        self.yaml_config_file = "config/pattern_learning_config.yaml"
        self.dynamic_fields_file = "config/dynamic_fields_config.yaml"
        
    def initialize(self) -> bool:
        """Inicializa la sesión de entrenamiento automático"""
        try:
            print(f"Initializing AUTOMATIC TRAINING Session...")
            print(f"File: {self.csv_file}")
            print(f"ERP Hint: {self.erp_hint or 'Auto-detect'}")
            print(f"Mode: AUTOMATIC (no manual confirmation)")
            print(f"Confidence resolution: Highest confidence wins")
            print(f"Confidence threshold: Only mappings > {self.confidence_threshold} will be included")
            print(f"Amount exception: Prioritize 'local' ALWAYS in name")
            
            # Verificar archivo
            if not os.path.exists(self.csv_file):
                print(f"File not found: {self.csv_file}")
                return False
            
            # Cargar CSV
            self.df = pd.read_csv(self.csv_file, encoding='utf-8')
            print(f"Loaded {len(self.df)} rows x {len(self.df.columns)} columns")
            
            # Importar módulos del sistema (MISMOS que manual trainer)
            try:
                from core.field_mapper import FieldMapper
                from core.field_detector import FieldDetector
                
                self.mapper = FieldMapper()
                self.detector = FieldDetector()
                print("System modules imported successfully")
                
            except ImportError as e:
                print(f"Failed to import system modules: {e}")
                return False
            
            # Cargar configuración de patrones aprendidos
            self._load_learned_patterns()
            
            return True
            
        except Exception as e:
            print(f"Initialization failed: {e}")
            return False
    
    def _load_learned_patterns(self):
        """Carga patrones previamente aprendidos (IGUAL que manual trainer)"""
        try:
            if os.path.exists(self.yaml_config_file):
                with open(self.yaml_config_file, 'r', encoding='utf-8') as f:
                    config = yaml.safe_load(f)
                    self.learned_patterns = config.get('learned_patterns', {})
                    print(f"Loaded {len(self.learned_patterns)} learned patterns")
            else:
                print("No previous learned patterns found")
        except Exception as e:
            print(f"Could not load learned patterns: {e}")
            self.learned_patterns = {}
    
    def run_automatic_training(self) -> Dict:
        """Ejecuta el entrenamiento automático SIN confirmación manual"""
        try:
            print(f"\nStarting AUTOMATIC FIELD TRAINING...")
            print(f"=" * 55)
            print(f"All decisions will be made automatically based on confidence")
            print(f"Special rule for 'amount': prioritize 'local' columns ALWAYS")
            print(f"Confidence threshold: {self.confidence_threshold} (only mappings above this will be included)")
            
            # Análisis inicial del DataFrame (IGUAL que manual trainer)
            print(f"CSV Columns ({len(self.df.columns)}):")
            for i, col in enumerate(self.df.columns, 1):
                print(f"  {i:2d}. {col}")
            
            # Detectar mappings automáticamente usando find_field_mapping
            print(f"\nFIELD MAPPING RESULTS:")
            field_mappings = {}
            unmapped_columns = []
            
            for column in self.df.columns:
                sample_data = self.df[column].dropna().head(100)  # Proporcionar datos de muestra
                mapping_result = self.mapper.find_field_mapping(column, self.erp_hint, sample_data)
                
                if mapping_result:
                    field_type, confidence = mapping_result
                    field_mappings[column] = {
                        'field_type': field_type,
                        'confidence': confidence
                    }
                else:
                    unmapped_columns.append(column)
            
            print(f"  Successful mappings: {len(field_mappings)}")
            print(f"  Failed mappings: {len(unmapped_columns)}")
            
            # Procesar mapeos automáticamente
            final_mappings = {}
            for column_name, mapping_info in field_mappings.items():
                field_type = mapping_info['field_type']
                confidence = mapping_info['confidence']
                
                self.training_stats['columns_processed'] += 1
                
                # FILTRO DE CONFIANZA: Solo incluir mapeos por encima del umbral
                if confidence < self.confidence_threshold:
                    print(f"  REJECTED: '{column_name}' -> {field_type} (confidence: {confidence:.3f} < {self.confidence_threshold})")
                    self.training_stats['rejected_low_confidence'] += 1
                    continue
                
                # Verificar conflictos (múltiples columnas para el mismo campo)
                existing_mappings = [col for col, info in final_mappings.items() if info['field_type'] == field_type]
                
                if existing_mappings:
                    # CONFLICTO DETECTADO - resolver automáticamente
                    print(f"  CONFLICT for '{field_type}': '{column_name}' vs {existing_mappings}")
                    
                    # Resolver conflicto automáticamente
                    winner_info = self._resolve_conflict_automatically(
                        field_type, 
                        [(column_name, confidence)] + [(col, final_mappings[col]['confidence']) for col in existing_mappings]
                    )
                    
                    if winner_info:
                        winner_column, winner_confidence, resolution_type = winner_info
                        
                        # Remover perdedores
                        for loser_col in existing_mappings:
                            if loser_col in final_mappings:
                                del final_mappings[loser_col]
                        
                        # Agregar ganador
                        final_mappings[winner_column] = {
                            'field_type': field_type,
                            'confidence': winner_confidence,
                            'resolution_type': resolution_type
                        }
                        
                        self.conflict_resolutions[field_type] = {
                            'winner': winner_column,
                            'resolution_type': resolution_type,
                            'all_candidates': [column_name] + existing_mappings
                        }
                        
                        if field_type == 'amount':
                            self.training_stats['amount_conflicts_resolved'] += 1
                        else:
                            self.training_stats['conflicts_resolved'] += 1
                        
                        print(f"    RESOLVED: '{winner_column}' wins ({resolution_type})")
                    
                else:
                    # Sin conflicto - agregar directamente
                    final_mappings[column_name] = {
                        'field_type': field_type,
                        'confidence': confidence,
                        'resolution_type': 'no_conflict'
                    }
                    print(f"  ACCEPTED: '{column_name}' -> {field_type} (confidence: {confidence:.3f})")
            
            # Actualizar user_decisions para compatibilidad
            self._update_user_decisions_from_mappings(final_mappings)
            
            # Finalizar entrenamiento
            result = self._finalize_automatic_training()
            
            return result
            
        except Exception as e:
            import traceback
            traceback.print_exc()
            return {'success': False, 'error': str(e)}
    
    def _resolve_conflict_automatically(self, field_type: str, candidates: List[Tuple[str, float]]) -> Optional[Tuple[str, float, str]]:
        """Resuelve conflictos automáticamente usando reglas predefinidas"""
        
        if not candidates:
            return None
        
        print(f"    RESOLVING CONFLICT for '{field_type}':")
        for column_name, confidence in candidates:
            print(f"      Candidate: '{column_name}' (confidence: {confidence:.3f})")
        
        # REGLA ESPECIAL PARA AMOUNT: Priorizar columnas con 'local' en el nombre
        if field_type == 'amount':
            return self._resolve_amount_conflict_with_local_priority(candidates)
        
        # REGLA GENERAL: Mayor confianza gana
        candidates_sorted = sorted(candidates, key=lambda x: x[1], reverse=True)
        winner_column, winner_confidence = candidates_sorted[0]
        
        print(f"    GENERAL RULE: '{winner_column}' has highest confidence ({winner_confidence:.3f})")
        return (winner_column, winner_confidence, 'highest_confidence')
    
    def _resolve_amount_conflict_with_local_priority(self, candidates: List[Tuple[str, float]]) -> Tuple[str, float, str]:
        """Resuelve conflictos de amount priorizando 'local' en el nombre"""
        
        print(f"    AMOUNT SPECIAL RULE: Checking for 'local' priority...")
        
        # PASO 1: Buscar candidatos que contengan palabras prioritarias
        priority_keywords = ['local', 'loc', 'domestico', 'domestic']
        priority_candidates = []
        
        for column_name, confidence in candidates:
            column_lower = column_name.lower()
            for keyword in priority_keywords:
                if keyword in column_lower:
                    priority_candidates.append((column_name, confidence, f'amount_priority_{keyword}'))
                    print(f"    FOUND PRIORITY CANDIDATE: '{column_name}' (contains '{keyword}')")
                    break
        
        # Si hay candidatos prioritarios, elegir el de mayor confianza entre ellos
        if priority_candidates:
            best_priority = max(priority_candidates, key=lambda x: x[1])
            print(f"    PRIORITY RULE: '{best_priority[0]}' contains '{best_priority[2].split('_')[-1]}'")
            return best_priority
        
        # PASO 3: Si no hay candidatos prioritarios, usar regla general (mayor confianza)
        candidates_sorted = sorted(candidates, key=lambda x: x[1], reverse=True)
        winner_column, winner_confidence = candidates_sorted[0]
        
        print(f"    FALLBACK RULE: '{winner_column}' has highest confidence ({winner_confidence:.3f})")
        return (winner_column, winner_confidence, 'amount_highest_confidence')
    
    def _update_user_decisions_from_mappings(self, final_mappings: Dict):
        """Actualiza user_decisions basado en mapeos finales (compatible con manual trainer)"""
        for column_name, mapping_info in final_mappings.items():
            field_type = mapping_info['field_type']
            confidence = mapping_info['confidence']
            resolution_type = mapping_info['resolution_type']
            
            # Determinar tipo de decisión automática
            if resolution_type == 'no_conflict':
                decision_type = 'automatic_no_conflict'
            else:
                decision_type = f'automatic_{resolution_type}'
            
            self.user_decisions[column_name] = {
                'field_type': field_type,
                'confidence': confidence,
                'decision_type': decision_type,
                'resolution_type': resolution_type
            }
            
            # Actualizar estadísticas
            if confidence > 0.8:
                self.training_stats['high_confidence_mappings'] += 1
            else:
                self.training_stats['low_confidence_mappings'] += 1
                
            self.training_stats['automatic_mappings'] += 1
    
    def _finalize_automatic_training(self) -> Dict:
        """Finaliza el entrenamiento automático y genera resultados (FORMATO COMPATIBLE)"""
        try:
            print(f"\nAUTOMATIC TRAINING FINALIZATION")
            print(f"=" * 40)
            
            # Generar reporte
            report_file = self._generate_training_report()
            
            # Crear CSV transformado con validaciones
            csv_result = self._create_transformed_csv()
            
            # Preparar resultado final
            result = {
                'success': True,
                'training_stats': self.training_stats,
                'user_decisions': self.user_decisions,
                'conflict_resolutions': self.conflict_resolutions,
                'report_file': report_file,
                **csv_result
            }
            
            return result
            
        except Exception as e:
            import traceback
            traceback.print_exc()
            return {'success': False, 'error': str(e)}
    
    def _generate_training_report(self) -> str:
        """Genera reporte de entrenamiento automático"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            report_file = f"automatic_training_report_{timestamp}.txt"
            
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(f"AUTOMATIC FIELD TRAINING SESSION REPORT\n")
                f.write(f"=" * 50 + "\n\n")
                
                f.write(f"Session Information:\n")
                f.write(f"  CSV File: {self.csv_file}\n")
                f.write(f"  ERP Hint: {self.erp_hint or 'Auto-detect'}\n")
                f.write(f"  Standard Fields: {len(self.standard_fields)}\n")
                f.write(f"  Mode: AUTOMATIC (no manual confirmation)\n")
                f.write(f"  Timestamp: {datetime.now().isoformat()}\n\n")
                
                f.write(f"Training Statistics:\n")
                for key, value in self.training_stats.items():
                    f.write(f"  {key.replace('_', ' ').title()}: {value}\n")
                f.write("\n")
                
                f.write(f"Automatic Decisions:\n")
                for column, decision in self.user_decisions.items():
                    f.write(f"  {column}: {decision['field_type']} ")
                    f.write(f"(confidence: {decision['confidence']:.3f}, ")
                    f.write(f"type: {decision['decision_type']})\n")
                f.write("\n")
                
                f.write(f"Conflict Resolutions:\n")
                for field_type, resolution in self.conflict_resolutions.items():
                    f.write(f"  {field_type}:\n")
                    f.write(f"    Winner: {resolution['winner']}\n")
                    f.write(f"    Resolution type: {resolution['resolution_type']}\n")
                    f.write(f"    All candidates: {resolution['all_candidates']}\n")
                f.write("\n")
                
                f.write(f"Final Mapping Table:\n")
                f.write(f"{'Campo Estándar':<25} | {'Columna Mapeada':<30} | {'Confianza':<10}\n")
                f.write(f"{'-'*25} | {'-'*30} | {'-'*10}\n")
                
                for standard_field in self.standard_fields:
                    mapped_column = "No mapeado"
                    confidence = "0.000"
                    
                    for column_name, decision in self.user_decisions.items():
                        if decision['field_type'] == standard_field:
                            mapped_column = column_name
                            confidence = f"{decision['confidence']:.3f}"
                            break
                  
                    f.write(f"{standard_field:<25} | {mapped_column:<30} | {confidence:<10}\n")
            
            print(f"Automatic training report saved to: {report_file}")
            return report_file
            
        except Exception as e:
            print(f"Could not generate report: {e}")
            return ""
    
    def _create_transformed_csv(self) -> Dict:
        """Crea dos CSV: uno de cabecera y otro de detalle con procesamiento numérico automático"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # Crear DataFrame con columnas renombradas
            transformed_df = self.df.copy()
            column_mapping = {}
            
            # Crear mapeo de columnas originales a campos estándar
            for column_name, decision in self.user_decisions.items():
                standard_field = decision['field_type']
                column_mapping[column_name] = standard_field
            
            # Renombrar columnas en el DataFrame
            transformed_df = transformed_df.rename(columns=column_mapping)
            
            # NUEVO: Procesar campos numéricos y calcular amount si es necesario
            transformed_df = self._process_numeric_fields_and_calculate_amount(transformed_df)
            
            # NUEVO: Realizar validaciones de balance por asiento
            balance_report = self._perform_balance_validations(transformed_df)
            
            # Determinar qué columnas van en header vs detail
            header_columns = []
            detail_columns = []
            
            for standard_field in self.standard_fields:
                if standard_field in transformed_df.columns:
                    # Campos de cabecera (únicos por journal_entry_id)
                    if standard_field in ['journal_entry_id', 'posting_date', 'fiscal_year', 
                                        'period_number', 'prepared_by', 'entry_date', 'entry_time', 'description']:
                        header_columns.append(standard_field)
                    else:
                        # Campos de detalle (múltiples líneas por journal_entry_id)
                        detail_columns.append(standard_field)
            
            # NUEVO: Ordenar por journal_entry_id de manera ascendente
            if 'journal_entry_id' in transformed_df.columns:
                transformed_df = transformed_df.sort_values('journal_entry_id', ascending=True)
                print(f"✓ Data sorted by journal_entry_id in ascending order")
            
            # Crear CSV de cabecera (datos únicos)
            if header_columns and 'journal_entry_id' in header_columns:
                header_df = transformed_df[header_columns].drop_duplicates(subset=['journal_entry_id'])
                # Ordenar header por journal_entry_id
                header_df = header_df.sort_values('journal_entry_id', ascending=True)
                header_file = f"automatic_training_header_{timestamp}.csv"
                header_df.to_csv(header_file, index=False, encoding='utf-8')
                print(f"Header CSV created: {header_file} ({len(header_df)} rows)")
            else:
                header_file = None
                print("No header CSV created (no journal_entry_id)")
            
            # Crear CSV de detalle (todas las líneas)
            if detail_columns:
                # Incluir journal_entry_id en detalle para linking
                if 'journal_entry_id' in transformed_df.columns and 'journal_entry_id' not in detail_columns:
                    detail_columns.insert(0, 'journal_entry_id')
                
                detail_df = transformed_df[detail_columns]
                # Ordenar detail por journal_entry_id
                if 'journal_entry_id' in detail_df.columns:
                    detail_df = detail_df.sort_values('journal_entry_id', ascending=True)
                detail_file = f"automatic_training_detail_{timestamp}.csv"
                detail_df.to_csv(detail_file, index=False, encoding='utf-8')
                print(f"Detail CSV created: {detail_file} ({len(detail_df)} rows)")
            else:
                detail_file = None
                print("No detail CSV created (no detail columns mapped)")
            
            return {
                'header_file': header_file,
                'detail_file': detail_file,
                'balance_report': balance_report,
                'csv_info': {
                    'header_columns': header_columns,
                    'detail_columns': detail_columns,
                    'total_standard_fields_mapped': len(self.user_decisions),
                    'unmapped_standard_fields': [f for f in self.standard_fields 
                                               if f not in [d['field_type'] for d in self.user_decisions.values()]]
                }
            }
            
        except Exception as e:
            print(f"Error creating transformed CSVs: {e}")
            return {'success': False, 'error': str(e)}
    
    def _process_numeric_fields_and_calculate_amount(self, df: pd.DataFrame) -> pd.DataFrame:
        """Procesa campos numéricos, limpia monedas y calcula amount si es necesario"""
        try:
            print(f"\n💰 PROCESSING NUMERIC FIELDS AND CALCULATING AMOUNT")
            print(f"-" * 50)
            
            # Lista de campos numéricos que necesitan limpieza
            numeric_fields = ['amount', 'debit_amount', 'credit_amount']
            
            # Limpiar campos numéricos existentes y RELLENAR CON CEROS
            cleaned_fields = []
            for field in numeric_fields:
                if field in df.columns:
                    print(f"Cleaning numeric field: {field}")
                    original_samples = df[field].dropna().head(3).tolist()
                    print(f"   Original values: {original_samples}")
                    
                    # Aplicar limpieza que ya incluye fillna con 0
                    df[field] = df[field].apply(self._clean_numeric_value_with_zero_fill)
                    
                    cleaned_samples = df[field].head(3).tolist()
                    print(f"   Cleaned values:  {cleaned_samples}")
                    
                    # Contar cuántos valores se rellenaron con cero
                    zero_count = (df[field] == 0.0).sum()
                    self.training_stats['zero_filled_fields'] += zero_count
                    print(f"   Zero-filled count: {zero_count}")
                    
                    cleaned_fields.append(field)
            
            # Verificar si necesitamos calcular amount
            has_amount = 'amount' in df.columns
            has_debit = 'debit_amount' in df.columns
            has_credit = 'credit_amount' in df.columns
            
            if not has_amount and has_debit and has_credit:
                print(f"💡 CALCULATING AMOUNT: amount = debit_amount - credit_amount")
                
                # Calcular amount como debit - credit (ya con ceros incluidos)
                df['amount'] = df['debit_amount'] - df['credit_amount']
                
                print(f"   ✓ Amount calculated for {len(df)} rows")
                print(f"   Sample calculated amounts: {df['amount'].head(3).tolist()}")
                
            elif has_amount:
                print(f"✓ Amount field already exists - using existing values")
            else:
                print(f"⚠️ Cannot calculate amount - missing debit_amount or credit_amount fields")
            
            # Mostrar resumen de limpieza
            if cleaned_fields:
                print(f"\n📊 NUMERIC FIELDS PROCESSING SUMMARY:")
                for field in cleaned_fields:
                    if field in df.columns:
                        non_null_count = df[field].notna().sum()
                        zero_count = (df[field] == 0.0).sum()
                        print(f"   {field}: {non_null_count} valid values, {zero_count} zeros")
            
            return df
            
        except Exception as e:
            print(f"Error processing numeric fields: {e}")
            return df
    
    def _clean_numeric_value_with_zero_fill(self, value) -> float:
        """Limpia un valor numérico eliminando texto de moneda y convirtiendo a float, RELLENANDO CON 0"""
        try:
            if pd.isna(value) or value == '' or value is None:
                return 0.0  # CAMBIO PRINCIPAL: Devolver 0.0 en lugar de None
            
            # Convertir a string si no lo es
            str_value = str(value).strip()
            
            if not str_value or str_value.lower() in ['', 'nan', 'none', 'null']:
                return 0.0  # CAMBIO PRINCIPAL: Devolver 0.0 en lugar de None
            
            # Remover espacios múltiples
            str_value = re.sub(r'\s+', ' ', str_value)
            
            # Patrones para limpiar monedas y texto
            # Ejemplos: "1000 EUR", "1,500.50 USD", "$1000", "1000€", "EUR 1000"
            currency_patterns = [
                r'\b[A-Z]{3}\b',        # EUR, USD, GBP, etc.
                r'[$€£¥₹₽¢]',          # Símbolos de moneda
                r'\b(USD|EUR|GBP|JPY|CAD|AUD|CHF|CNY|SEK|NOK|DKK|PLN|CZK|HUF|BGN|RON|HRK|RUB|TRY|BRL|MXN|ARS|CLP|PEN|COP|UYU|PYG|BOB|VEF|GYD|SRD|TTD|JMD|BBD|BSD|KYD|XCD|AWG|ANG|CUP|DOP|GTQ|HNL|NIO|CRC|PAB|BZD|SVC|HTG)\b',  # Códigos ISO comunes
                r'\b(DOLLAR|EURO|POUND|YEN|PESO|REAL|FRANC|KRONA|KRONE|ZLOTY|FORINT|LEU|LIRA|RUBLE|YUAN|RUPEE)\b',  # Nombres de monedas en inglés
                r'\b(DOLAR|EUROS|LIBRA|YENES|PESOS|REALES|FRANCOS|CORONAS|RUBLOS|YUANES|RUPIAS)\b'  # Nombres en español
            ]
            
            # Aplicar limpieza de monedas
            cleaned_value = str_value
            for pattern in currency_patterns:
                cleaned_value = re.sub(pattern, '', cleaned_value, flags=re.IGNORECASE)
            
            # Limpiar caracteres no numéricos excepto punto, coma y signo menos
            cleaned_value = re.sub(r'[^0-9.,-]', '', cleaned_value)
            
            # Manejar signos negativos
            is_negative = cleaned_value.count('-') % 2 == 1  # Impar = negativo
            cleaned_value = cleaned_value.replace('-', '')
            
            if not cleaned_value or not any(c.isdigit() for c in cleaned_value):
                return 0.0  # CAMBIO PRINCIPAL: Devolver 0.0 en lugar de None
            
            # Detectar formato de número mejorado
            if '.' in cleaned_value and ',' in cleaned_value:
                # Ambos presentes: detectar cuál es el decimal
                last_dot = cleaned_value.rfind('.')
                last_comma = cleaned_value.rfind(',')
                
                if last_dot > last_comma:
                    # Punto como decimal: "1,234.56"
                    cleaned_value = cleaned_value.replace(',', '')
                else:
                    # Coma como decimal: "1.234,56"
                    cleaned_value = cleaned_value.replace('.', '').replace(',', '.')
            
            elif ',' in cleaned_value:
                # Solo comas
                comma_parts = cleaned_value.split(',')
                if len(comma_parts) == 2 and len(comma_parts[1]) <= 3:
                    # Probablemente decimal: "1234,56"
                    cleaned_value = cleaned_value.replace(',', '.')
                else:
                    # Probablemente separador de miles: "1,234"
                    cleaned_value = cleaned_value.replace(',', '')
            
            elif '.' in cleaned_value:
                # Solo puntos - LÓGICA MEJORADA
                dot_parts = cleaned_value.split('.')
                if len(dot_parts) >= 2:
                    last_part = dot_parts[-1]
                    # Si la última parte tiene 1-2 dígitos, probablemente es decimal
                    if len(last_part) <= 2 and last_part.isdigit():
                        # Formato europeo: "229.006.45" -> separadores de miles + decimal
                        # Unir todas las partes excepto la última como entero
                        integer_part = ''.join(dot_parts[:-1])
                        decimal_part = last_part
                        cleaned_value = f"{integer_part}.{decimal_part}"
                    else:
                        # Todos los puntos son separadores de miles: "1.234.567"
                        cleaned_value = cleaned_value.replace('.', '')
            
            
            # Convertir a float
            if cleaned_value and cleaned_value not in ['.', ',', '-', '+']:
                result = float(cleaned_value)
                return -result if is_negative else result
            else:
                return 0.0  # CAMBIO PRINCIPAL: Devolver 0.0 en lugar de None
                
        except (ValueError, TypeError):
            # Si no se puede convertir, intentar extraer números
            try:
                # Buscar patrones numéricos más complejos
                numbers = re.findall(r'-?\d+[.,]?\d*', str(value))
                if numbers:
                    # Tomar el primer número encontrado y limpiarlo recursivamente
                    first_num = numbers[0].replace(',', '.')
                    return float(first_num)
                return 0.0  # CAMBIO PRINCIPAL: Devolver 0.0 en lugar de None
            except:
                return 0.0  # CAMBIO PRINCIPAL: Devolver 0.0 en lugar de None

    def _perform_balance_validations(self, df: pd.DataFrame) -> Dict:
        """Realiza validaciones de balance por asiento y en total"""
        try:
            print(f"\n⚖️ PERFORMING BALANCE VALIDATIONS")
            print(f"-" * 40)
            
            balance_report = {
                'total_debit_sum': 0.0,
                'total_credit_sum': 0.0,
                'total_balance_difference': 0.0,
                'is_balanced': False,
                'entry_balance_check': [],
                'unbalanced_entries': [],
                'entries_count': 0,
                'balanced_entries_count': 0
            }
            
            has_debit = 'debit_amount' in df.columns
            has_credit = 'credit_amount' in df.columns
            has_journal_id = 'journal_entry_id' in df.columns
            
            if not (has_debit and has_credit):
                print("⚠️ Cannot perform balance validation - missing debit_amount or credit_amount")
                return balance_report
            
            # Calcular totales generales
            total_debit = df['debit_amount'].sum()
            total_credit = df['credit_amount'].sum()
            total_difference = total_debit - total_credit
            
            balance_report['total_debit_sum'] = total_debit
            balance_report['total_credit_sum'] = total_credit
            balance_report['total_balance_difference'] = total_difference
            balance_report['is_balanced'] = abs(total_difference) < 0.01  # Tolerancia para decimales
            
            self.training_stats['total_debit_sum'] = total_debit
            self.training_stats['total_credit_sum'] = total_credit
            self.training_stats['balance_checks_performed'] = 1
            
            print(f"📊 TOTAL BALANCE CHECK:")
            print(f"   Total Debit:  {total_debit:,.2f}")
            print(f"   Total Credit: {total_credit:,.2f}")
            print(f"   Difference:   {total_difference:,.2f}")
            print(f"   Is Balanced:  {'✓ YES' if balance_report['is_balanced'] else '✗ NO'}")
            
            # Validación por asiento si existe journal_entry_id
            if has_journal_id:
                print(f"\n📋 ENTRY-LEVEL BALANCE CHECK:")
                
                # Agrupar por journal_entry_id
                grouped = df.groupby('journal_entry_id').agg({
                    'debit_amount': 'sum',
                    'credit_amount': 'sum'
                }).reset_index()
                
                # Calcular diferencia por asiento
                grouped['balance_difference'] = grouped['debit_amount'] - grouped['credit_amount']
                grouped['is_balanced'] = abs(grouped['balance_difference']) < 0.01
                
                balance_report['entries_count'] = len(grouped)
                balance_report['balanced_entries_count'] = grouped['is_balanced'].sum()
                
                # Identificar asientos desbalanceados
                unbalanced = grouped[~grouped['is_balanced']]
                balance_report['unbalanced_entries'] = unbalanced.to_dict('records')
                self.training_stats['unbalanced_entries'] = len(unbalanced)
                
                print(f"   Total Entries: {len(grouped)}")
                print(f"   Balanced:      {balance_report['balanced_entries_count']}")
                print(f"   Unbalanced:    {len(unbalanced)}")
                
                if len(unbalanced) > 0:
                    print(f"\n⚠️ UNBALANCED ENTRIES DETECTED:")
                    for _, entry in unbalanced.head(10).iterrows():  # Mostrar primeros 10
                        print(f"   Entry {entry['journal_entry_id']}: Debit {entry['debit_amount']:,.2f} - Credit {entry['credit_amount']:,.2f} = {entry['balance_difference']:,.2f}")
                    
                    if len(unbalanced) > 10:
                        print(f"   ... and {len(unbalanced) - 10} more unbalanced entries")
                else:
                    print(f"   ✓ All entries are balanced!")
                
                # Guardar detalles para el reporte
                balance_report['entry_balance_check'] = grouped.to_dict('records')
            
            else:
                print("   No journal_entry_id found - skipping entry-level validation")
            
            return balance_report
            
        except Exception as e:
            print(f"Error performing balance validations: {e}")
            return balance_report


def run_automatic_training(csv_file: str, erp_hint: str = None) -> Dict:
    """Función principal para ejecutar entrenamiento automático"""
    try:
        print(f"🤖 AUTOMATIC CONFIRMATION TRAINER")
        print(f"=" * 50)
        print(f"Starting automatic training session...")
        print(f"File: {csv_file}")
        print(f"ERP: {erp_hint or 'Auto-detect'}")
        print(f"Decision mode: AUTOMATIC (no confirmation required)")
        print(f"Quality filter: Only confidence > 0.75 accepted")
        print(f"Special rule: AMOUNT field prioritizes 'local' ALWAYS")
        print(f"Enhancement: Zero-fill empty numeric fields & balance validation")
        print()
        
        # Crear sesión de entrenamiento automático
        session = AutomaticConfirmationTrainingSession(csv_file, erp_hint)
        
        # Inicializar
        if not session.initialize():
            return {'success': False, 'error': 'Initialization failed'}
        
        # Ejecutar entrenamiento automático
        result = session.run_automatic_training()
        
        if result['success']:
            print(f"\n✅ AUTOMATIC TRAINING COMPLETED SUCCESSFULLY!")
            print(f"📊 Statistics:")
            for key, value in result['training_stats'].items():
                print(f"   • {key.replace('_', ' ').title()}: {value}")
            
            if result.get('csv_info'):
                csv_info = result['csv_info']
                if csv_info.get('header_columns'):
                    print(f"   • Header columns: {', '.join(csv_info['header_columns'])}")
                if csv_info.get('detail_columns'):
                    print(f"   • Detail columns: {', '.join(csv_info['detail_columns'])}")
            
            # Mostrar información de balance si está disponible
            if result.get('balance_report'):
                balance = result['balance_report']
                print(f"\n⚖️ BALANCE VALIDATION RESULTS:")
                print(f"   • Total Balance: {'✓ BALANCED' if balance['is_balanced'] else '✗ UNBALANCED'}")
                print(f"   • Total Debit: {balance['total_debit_sum']:,.2f}")
                print(f"   • Total Credit: {balance['total_credit_sum']:,.2f}")
                if balance['entries_count'] > 0:
                    print(f"   • Entries Balanced: {balance['balanced_entries_count']}/{balance['entries_count']}")
                    print(f"   • Unbalanced Entries: {len(balance.get('unbalanced_entries', []))}")
            
            print(f"\nAUTOMATIC TRAINING ACHIEVEMENTS:")
            print(f"   • Automatic mappings: {result['training_stats']['automatic_mappings']}")
            print(f"   • Conflicts resolved: {result['training_stats']['conflicts_resolved']}")
            print(f"   • Amount conflicts resolved: {result['training_stats']['amount_conflicts_resolved']}")
            print(f"   • High confidence decisions: {result['training_stats']['high_confidence_mappings']}")
            print(f"   • Rejected low confidence: {result['training_stats']['rejected_low_confidence']}")
            print(f"   • Zero-filled fields: {result['training_stats']['zero_filled_fields']}")
            print(f"   • Standard fields only: {len(session.standard_fields)}")
            print(f"   • LOCAL PRIORITY RULE: Active for amount conflicts")
            print(f"   • CONFIDENCE FILTER: Only mappings > {session.confidence_threshold} included")
            print(f"   • ORDER BY: journal_entry_id ASC applied to both header and detail")
        
        return result
        
    except Exception as e:
        print(f"Automatic training failed: {e}")
        import traceback
        traceback.print_exc()
        return {'success': False, 'error': str(e)}


def main():
    """Función principal - COMPATIBLE con manual_confirmation_trainer.py"""
    if len(sys.argv) < 2:
        print("AUTOMATIC CONFIRMATION TRAINER - ENHANCED")
        print("=" * 50)
        print("Training with AUTOMATIC DECISIONS - no manual confirmation required")
        print()
        print("FEATURES:")
        print("  • ALL decisions made automatically based on confidence")
        print("  • High confidence: automatic assignment")
        print("  • Confidence filter: Only mappings > 0.75 are included")
        print("  • Conflicts resolved by highest confidence")
        print("  • Special rule for 'amount': prioritizes 'local' ALWAYS")
        print("  • Automatic numeric field cleaning and amount calculation")
        print("  • Zero-fill empty numeric fields (debit, credit, amount)")
        print("  • Balance validation by entry and total")
        print("  • Ordered output by journal_entry_id (ascending)")
        print("  • Same standard fields (17 fields total)")
        print("  • Same CSV outputs as manual trainer")
        print("  • Compatible with main_global.py")
        print()
        print("STANDARD FIELDS:")
        standard_fields = [
            'journal_entry_id', 'line_number', 'description', 'line_description',
            'posting_date', 'fiscal_year', 'period_number', 'gl_account_number',
            'amount', 'debit_amount', 'credit_amount', 'debit_credit_indicator',
            'prepared_by', 'entry_date', 'entry_time', 'gl_account_name', 'vendor_id'
        ]
        for i, field in enumerate(standard_fields, 1):
            print(f"  {i:2d}. {field}")
        print()
        print("Usage:")
        print("  python automatic_confirmation_trainer.py <csv_file> [erp_hint]")
        print()
        print("Examples:")
        print("  python automatic_confirmation_trainer.py data/journal.csv")
        print("  python automatic_confirmation_trainer.py data/journal.csv SAP")
        print("  python automatic_confirmation_trainer.py data/journal.csv Oracle")
        print()
        print("OUTPUT FILES:")
        print("  • automatic_training_report_TIMESTAMP.txt")
        print("  • automatic_training_header_TIMESTAMP.csv (ordered by journal_entry_id)")
        print("  • automatic_training_detail_TIMESTAMP.csv (ordered by journal_entry_id)")
        print()
        print("NUMERIC PROCESSING:")
        print("  • Cleans currency symbols and text from numeric fields")
        print("  • Handles different number formats (1,234.56 vs 1.234,56)")
        print("  • Fills empty numeric fields with 0.0 (NEW)")
        print("  • Calculates amount = debit_amount - credit_amount if needed")
        print("  • Validates total balance: debit_sum == credit_sum")
        print("  • Checks balance by journal entry: debit - credit = 0 per entry")
        print("  • Reports unbalanced entries in detail")
        return
    
    # Extraer parámetros
    csv_file = sys.argv[1]
    erp_hint = sys.argv[2] if len(sys.argv) > 2 else None
    
    # Ejecutar entrenamiento automático
    result = run_automatic_training(csv_file, erp_hint)
    
    if not result['success']:
        print(f"❌ Training failed: {result.get('error')}")
        sys.exit(1)
    
    print(f"\n✅ Automatic training completed successfully!")


if __name__ == "__main__":
    main()